{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/slachitoff/Music-Source-Separation/blob/main/Music_Source_Separation_with_U_Net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znNGTvI5pHJt",
        "outputId": "6ed16ddf-e0cb-4ec7-86b6-a50e4c1e621a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting musdb\n",
            "  Downloading musdb-0.4.2-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.10/dist-packages (from musdb) (1.25.2)\n",
            "Collecting stempeg>=0.2.3 (from musdb)\n",
            "  Downloading stempeg-0.2.3-py3-none-any.whl (963 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m963.5/963.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyaml (from musdb)\n",
            "  Downloading pyaml-24.4.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from musdb) (4.66.4)\n",
            "Collecting ffmpeg-python>=0.2.0 (from stempeg>=0.2.3->musdb)\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml->musdb) (6.0.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python>=0.2.0->stempeg>=0.2.3->musdb) (0.18.3)\n",
            "Installing collected packages: pyaml, ffmpeg-python, stempeg, musdb\n",
            "Successfully installed ffmpeg-python-0.2.0 musdb-0.4.2 pyaml-24.4.0 stempeg-0.2.3\n",
            "Collecting mir_eval\n",
            "  Downloading mir_eval-0.7.tar.gz (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.7/90.7 kB\u001b[0m \u001b[31m877.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from mir_eval) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from mir_eval) (1.11.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from mir_eval) (0.18.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from mir_eval) (1.16.0)\n",
            "Building wheels for collected packages: mir_eval\n",
            "  Building wheel for mir_eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mir_eval: filename=mir_eval-0.7-py3-none-any.whl size=100704 sha256=70de0d635f1a7b3b4a2b9ddbdfd45db3cb9ba6206b14410468d6389ad34fd432\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/2f/0d/dda9c4c77a170e21356b6afa2f7d9bb078338634ba05d94e3f\n",
            "Successfully built mir_eval\n",
            "Installing collected packages: mir_eval\n",
            "Successfully installed mir_eval-0.7\n"
          ]
        }
      ],
      "source": [
        "!pip install musdb\n",
        "!pip install mir_eval\n",
        "\n",
        "import musdb\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchaudio\n",
        "import torchaudio.transforms as T\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from torchsummary import summary\n",
        "import random\n",
        "import gc\n",
        "import torch.multiprocessing as mp\n",
        "import numpy as np\n",
        "import os\n",
        "import logging\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "import mir_eval\n",
        "from torch.utils.data._utils.collate import default_collate\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "mp.set_start_method('spawn', force=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K974v6bzp06i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7efaf35a-ff91-4cc5-f80a-80d077ce8d9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4sXem6Y6rj4Y"
      },
      "outputs": [],
      "source": [
        "mus = musdb.DB(root='/content/drive/MyDrive/musdb18', subsets='train', split='train')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjODSkUvxbCK"
      },
      "source": [
        "The `SpectrogramPreprocessor` class takes tracks from the MUSDB10 dataset and transforms them into complex spectrograms, normalizes them, and saves the spectrograms to a directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OviIDKK9rz7-"
      },
      "outputs": [],
      "source": [
        "class SpectrogramPreprocessor:\n",
        "    def __init__(self, musdb, chunk_duration=6, target_sr=22050, original_sr=44100, transform=None, debug=False, save_dir=None):\n",
        "        assert isinstance(chunk_duration, int) and chunk_duration > 0, \"chunk_duration must be a positive integer\"\n",
        "        assert isinstance(target_sr, int) and target_sr > 0, \"target_sr must be a positive integer\"\n",
        "        assert isinstance(original_sr, int) and original_sr > 0, \"original_sr must be a positive integer\"\n",
        "\n",
        "        self.musdb = musdb.tracks  # List of tracks from the MUSDB18 dataset\n",
        "        self.chunk_duration = chunk_duration  # Duration of each audio chunk\n",
        "        self.target_sr = target_sr  # Target sample rate for resampling\n",
        "        self.chunk_length = self.target_sr * self.chunk_duration  # Length of each chunk in samples\n",
        "        self.original_sr = original_sr  # Original sample rate of the audio\n",
        "        self.transform = transform  # Optional transform to apply to spectrograms\n",
        "        self.debug = debug  # Debug flag\n",
        "        self.save_dir = save_dir or os.path.join(musdb.root, 'spectrograms')  # Directory to save spectrograms\n",
        "        os.makedirs(self.save_dir, exist_ok=True)  # Create save directory if it doesn't exist\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'  # Set device to GPU if available\n",
        "\n",
        "    # Normalizes a spectrogram's magnitude\n",
        "    def normalize_magnitude(self, spec, lower_percentile=5, upper_percentile=95):\n",
        "        magnitude = torch.abs(spec)  # Get magnitude of the spectrogram\n",
        "        phase = torch.angle(spec)  # Get phase of the spectrogram\n",
        "        dynamic_range = magnitude.max() - magnitude.min()  # Compute dynamic range\n",
        "\n",
        "        if dynamic_range < 1e-8:\n",
        "            return spec  # Return original spectrogram if dynamic range is too small\n",
        "\n",
        "        epsilon = 1e-6  # Small value for numerical stability\n",
        "        magnitude = torch.log1p(magnitude + epsilon)  # Log scale transformation\n",
        "\n",
        "        lower_bound = torch.quantile(magnitude, lower_percentile / 100.0)  # Compute lower bound\n",
        "        upper_bound = torch.quantile(magnitude, upper_percentile / 100.0)  # Compute upper bound\n",
        "        if upper_bound <= lower_bound:\n",
        "            return spec  # Return original spectrogram if bounds are invalid\n",
        "\n",
        "        # Normalize the magnitude\n",
        "        normalized_magnitude = torch.clip((magnitude - lower_bound) / (upper_bound - lower_bound), 0, 1)\n",
        "        normalized_spec = torch.polar(normalized_magnitude, phase)  # Recombine normalized magnitude with original phase\n",
        "\n",
        "        return normalized_spec\n",
        "\n",
        "    # Resamples audio and converts to mono\n",
        "    def resample_audio(self, audio_np, original_sr, target_sr):\n",
        "        if audio_np.shape[1] > audio_np.shape[0]:\n",
        "            audio_tensor = torch.from_numpy(audio_np).float()  # Convert to tensor\n",
        "        else:\n",
        "            audio_tensor = torch.from_numpy(audio_np.T).float()  # Transpose if needed\n",
        "        if original_sr != target_sr:\n",
        "            resampler = torchaudio.transforms.Resample(original_sr, target_sr)  # Resample audio\n",
        "            audio_tensor = resampler(audio_tensor)\n",
        "        if audio_tensor.shape[0] > 1:\n",
        "            audio_tensor = torch.mean(audio_tensor, dim=0, keepdim=True)  # Convert to mono if multi-channel\n",
        "        return audio_tensor\n",
        "\n",
        "    # Process each audio file into chunks and compute the spectrograms.\n",
        "    def process_audio_file(self, track):\n",
        "        audio = torch.tensor(track.audio.T, dtype=torch.float32)  # Convert audio to tensor\n",
        "\n",
        "        if self.original_sr != track.rate:\n",
        "            raise ValueError(f\"Track {track.name} has a different sampling rate: {track.rate}. Expected: {self.original_sr}\")\n",
        "\n",
        "        num_chunks = max(1, audio.shape[1] // self.chunk_length)  # Calculate number of chunks\n",
        "\n",
        "        for chunk_idx in range(num_chunks):\n",
        "            start = chunk_idx * self.chunk_length  # Start index of the chunk\n",
        "            end = min(audio.shape[1], start + self.chunk_length)  # End index of the chunk\n",
        "            audio_chunk = audio[:, start:end]  # Extract audio chunk\n",
        "\n",
        "            mixed_spectrogram = self.compute_and_save_spectrogram(track.name, chunk_idx, audio_chunk)  # Compute spectrogram\n",
        "\n",
        "            if torch.is_complex(mixed_spectrogram):\n",
        "                mixed_spectrogram = torch.view_as_real(mixed_spectrogram)  # Convert complex spectrogram to real\n",
        "\n",
        "            print(f\"Chunk Index: {chunk_idx}\")\n",
        "            print(f\"Mixed Spectrogram Shape: {mixed_spectrogram.shape}\")\n",
        "\n",
        "            for source_name, source in track.sources.items():\n",
        "                source_audio_chunk = torch.tensor(source.audio[start:end].T, dtype=torch.float32)  # Extract source audio chunk\n",
        "                source_spectrogram = self.compute_and_save_spectrogram(track.name, chunk_idx, source_audio_chunk, source_name)  # Compute source spectrogram\n",
        "\n",
        "                if torch.is_complex(source_spectrogram):\n",
        "                    source_spectrogram = torch.view_as_real(source_spectrogram)  # Convert complex spectrogram to real\n",
        "\n",
        "                print(f\"Source: {source_name}, Source Spectrogram Shape: {source_spectrogram.shape}\")\n",
        "\n",
        "    # Compute and save a spectrogram for a given audio file and chunk index.\n",
        "    def compute_and_save_spectrogram(self, track_name, chunk_idx, audio_chunk, source_name=None):\n",
        "        base_filename = f\"{track_name}_chunk{chunk_idx}\"  # Base filename for saving\n",
        "        spectrogram_path = os.path.join(self.save_dir, f\"{base_filename}_{'mixed' if source_name is None else source_name}_source.pt\")  # Path to save spectrogram\n",
        "\n",
        "        try:\n",
        "            audio_chunk = self.resample_audio(audio_chunk.numpy(), self.original_sr, self.target_sr)  # Resample audio\n",
        "            spectrogram = self.audio_to_complex_spectrogram(audio_chunk)  # Compute spectrogram\n",
        "\n",
        "            if spectrogram.dim() > 3 and spectrogram.size(0) == 1:\n",
        "                spectrogram = spectrogram.squeeze(0)  # Squeeze dimension if needed\n",
        "            torch.save(spectrogram, spectrogram_path)  # Save spectrogram\n",
        "            return spectrogram\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to compute or save spectrogram for {track_name}: {str(e)}\")  # Print error message\n",
        "            return None\n",
        "\n",
        "    # Compute a complex spectrogram from an audio signal.\n",
        "    def audio_to_complex_spectrogram(self, audio, n_fft=1024, hop_length=512):\n",
        "        if not isinstance(audio, torch.Tensor):\n",
        "            audio = torch.tensor(audio, dtype=torch.float32)  # Convert to tensor if not already\n",
        "        audio = audio.to(self.device)  # Move audio to device\n",
        "\n",
        "        if audio.size(1) < audio.size(0):\n",
        "            audio = audio.transpose(0, 1)  # Transpose if needed\n",
        "\n",
        "        if audio.size(1) < n_fft:\n",
        "            padding = n_fft - audio.size(1)  # Compute padding\n",
        "            audio = F.pad(audio, (0, padding), \"constant\", 0)  # Pad audio\n",
        "\n",
        "        if audio.abs().max().item() < 1e-8:\n",
        "            return torch.zeros((1, n_fft // 2 + 1, max(1, audio.size(1) // hop_length + 1)), dtype=torch.cfloat, device=self.device)  # Return zero tensor if audio is silent\n",
        "\n",
        "        window = torch.hann_window(n_fft, device=self.device)  # Hann window for STFT\n",
        "        complex_spec = torch.stft(audio, n_fft=n_fft, hop_length=hop_length, window=window, return_complex=True)  # Compute STFT\n",
        "\n",
        "        normalized_spec = self.normalize_magnitude(complex_spec)  # Normalize spectrogram\n",
        "\n",
        "        return normalized_spec\n",
        "\n",
        "    # Precompute and save spectrograms for all audio files in the folder.\n",
        "    def precompute_spectrograms(self):\n",
        "        for track in self.musdb:\n",
        "            print(f\"Processing track {track.name}\")  # Print track being processed\n",
        "            self.process_audio_file(track)  # Process each track\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UOvFL_Tg2n-p"
      },
      "outputs": [],
      "source": [
        "# Converts a set of .pt files to HDF5 format for fast access\n",
        "def convert_pt_to_hdf5(pt_dir, hdf5_file):\n",
        "    # Create a new HDF5 file\n",
        "    with h5py.File(hdf5_file, 'w') as hdf5:\n",
        "        # Loop through all .pt files in the directory\n",
        "        for filename in os.listdir(pt_dir):\n",
        "            if filename.endswith('.pt'):\n",
        "                # Construct the full file path\n",
        "                filepath = os.path.join(pt_dir, filename)\n",
        "                # Load the data from the .pt file\n",
        "                data = torch.load(filepath)\n",
        "                # Ensure the data is on CPU\n",
        "                data = data.cpu()\n",
        "                # Use the filename without the extension as the dataset name\n",
        "                dataset_name = filename[:-3]\n",
        "                # Convert the torch tensor to numpy and save to HDF5\n",
        "                hdf5.create_dataset(dataset_name, data=data.numpy(), compression=\"gzip\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3IngRluXsaK"
      },
      "source": [
        "The `SpectrogramTransforms` class applies various data augmentation techniques to spectrograms.\n",
        "It includes time masking, frequency masking, noise addition, and spectrogram augmentation through random time and frequency\n",
        "stripes dropping."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDvmXdgbr4-V"
      },
      "outputs": [],
      "source": [
        "class SpectrogramTransforms:\n",
        "    def __init__(self,\n",
        "                 p_time_mask=0.5,\n",
        "                 p_freq_mask=0.5,\n",
        "                 time_mask_param=40,\n",
        "                 freq_mask_param=40,\n",
        "                 time_stripes_num=3,\n",
        "                 freq_stripes_num=3,\n",
        "                 p_add_noise=0.5,\n",
        "                 min_snr_db=10,\n",
        "                 max_snr_db=30,\n",
        "                 p_time_warp=0.3,\n",
        "                 time_warp_param=80):\n",
        "\n",
        "        # Probability of applying time masking\n",
        "        self.p_time_mask = p_time_mask\n",
        "        # Probability of applying frequency masking\n",
        "        self.p_freq_mask = p_freq_mask\n",
        "        # Parameters for time and frequency masking from torchaudio\n",
        "        self.time_masking = T.TimeMasking(time_mask_param)\n",
        "        self.freq_masking = T.FrequencyMasking(freq_mask_param)\n",
        "        # Number of time and frequency stripes to drop in spec_augment\n",
        "        self.time_stripes_num = time_stripes_num\n",
        "        self.freq_stripes_num = freq_stripes_num\n",
        "        # Probability of adding noise\n",
        "        self.p_add_noise = p_add_noise\n",
        "        # Minimum and maximum Signal-to-Noise Ratio (SNR) for added noise\n",
        "        self.min_snr_db = min_snr_db\n",
        "        self.max_snr_db = max_snr_db\n",
        "\n",
        "    def __call__(self, spec):\n",
        "        # Apply time masking with a given probability\n",
        "        if random.random() < self.p_time_mask:\n",
        "            spec = self.time_masking(spec)\n",
        "        # Apply frequency masking with a given probability\n",
        "        if random.random() < self.p_freq_mask:\n",
        "            spec = self.freq_masking(spec)\n",
        "        # Add noise with a given probability\n",
        "        if random.random() < self.p_add_noise:\n",
        "            spec = self.add_noise(spec)\n",
        "        # Apply spectrogram augmentation\n",
        "        return self.spec_augment(spec)\n",
        "\n",
        "    def add_noise(self, spec):\n",
        "        # Select a random SNR value within the specified range\n",
        "        snr_db = random.uniform(self.min_snr_db, self.max_snr_db)\n",
        "        # Calculate the amplitude of the noise\n",
        "        noise_amp = spec.abs().max() / (10 ** (snr_db / 20))\n",
        "        # Generate noise with the same shape as the spectrogram\n",
        "        noise = torch.randn_like(spec) * noise_amp\n",
        "        # Add noise to the spectrogram\n",
        "        return spec + noise\n",
        "\n",
        "    def time_warp(self, spec):\n",
        "        # Get the number of time steps in the spectrogram\n",
        "        time_steps = spec.size(-1)\n",
        "        if time_steps > self.time_warp_param:\n",
        "            # Select a random center point for time warping\n",
        "            center = random.randint(self.time_warp_param, time_steps - self.time_warp_param)\n",
        "            # Create a copy of the spectrogram\n",
        "            warped = spec.clone()\n",
        "            # Warp the time axis around the center point\n",
        "            warped[:, :, center - self.time_warp_param:center + self.time_warp_param] = \\\n",
        "                spec[:, :, center - self.time_warp_param // 2:center + self.time_warp_param // 2]\n",
        "            return warped\n",
        "        return spec\n",
        "\n",
        "    def spec_augment(self, spec):\n",
        "        # Get the dimensions of the spectrogram\n",
        "        time_dim, freq_dim = spec.size(-1), spec.size(-2)\n",
        "        # Determine the width of time and frequency drops\n",
        "        time_drop_width = max(1, min(time_dim // 10, time_dim - 1))\n",
        "        freq_drop_width = max(1, min(freq_dim // 10, freq_dim - 1))\n",
        "\n",
        "        # Drop random time stripes in the spectrogram\n",
        "        for _ in range(self.time_stripes_num):\n",
        "            start = random.randint(0, time_dim - time_drop_width)\n",
        "            end = start + time_drop_width\n",
        "            spec[..., start:end] = 0\n",
        "\n",
        "        # Drop random frequency stripes in the spectrogram\n",
        "        for _ in range(self.freq_stripes_num):\n",
        "            start = random.randint(0, freq_dim - freq_drop_width)\n",
        "            end = start + freq_drop_width\n",
        "            spec[..., :, start:end] = 0\n",
        "\n",
        "        return spec\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9F0FC6PX4Ym"
      },
      "source": [
        "The `AudioDataset` class represents a custom dataset for handling audio data stored in an HDF5 file.\n",
        "It loads mixed and source spectrograms for a given list of tracks, with the option of applying the previously defined transformations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Qes5xZM78dX"
      },
      "outputs": [],
      "source": [
        "class AudioDataset(Dataset):\n",
        "    def __init__(self, hdf5_path, track_list, transform=None):\n",
        "       # Path to the HDF5 file containing the dataset\n",
        "        self.hdf5_path = hdf5_path\n",
        "        # List of tracks to be loaded from the HDF5 file\n",
        "        self.track_list = track_list\n",
        "        # Optional transform to be applied to the spectrograms\n",
        "        self.transform = transform\n",
        "        # Open the HDF5 file for reading\n",
        "        self.hdf5_file = h5py.File(self.hdf5_path, 'r')\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get the base name of the track at the given index\n",
        "        track_base = self.track_list[idx]\n",
        "        # List of source instruments\n",
        "        sources = ['bass', 'drums', 'other', 'vocals']\n",
        "        # Construct the name for the mixed spectrogram in the HDF5 file\n",
        "        mixed_name = f\"{track_base}_mixed_source\"\n",
        "        # Load and convert the mixed spectrogram from the HDF5 file\n",
        "        mixed_spectrogram = torch.view_as_real(torch.from_numpy(self.hdf5_file[mixed_name][()]))\n",
        "\n",
        "        # Apply the optional transform to the mixed spectrogram\n",
        "        if self.transform:\n",
        "            mixed_spectrogram = self.transform(mixed_spectrogram)\n",
        "\n",
        "        # Create a list to store the source spectrograms\n",
        "        source_spectrograms = []\n",
        "        for source in sources:\n",
        "            # Construct the name for the source spectrogram in the HDF5 file\n",
        "            full_name = f\"{track_base}_{source}_source\"\n",
        "            # Load and convert the source spectrogram from the HDF5 file\n",
        "            complex_array = self.hdf5_file[full_name][()]\n",
        "            tensor = torch.view_as_real(torch.from_numpy(complex_array))\n",
        "            # Apply the optional transform to the source spectrogram\n",
        "            if self.transform:\n",
        "                tensor = self.transform(tensor)\n",
        "            # Add the transformed source spectrogram to the list\n",
        "            source_spectrograms.append(tensor)\n",
        "\n",
        "        # Concatenate all source spectrograms along the channel dimension\n",
        "        source_spectrograms = torch.cat(source_spectrograms, dim=0)\n",
        "\n",
        "        # Return the mixed spectrogram and the concatenated source spectrograms\n",
        "        return mixed_spectrogram, source_spectrograms\n",
        "\n",
        "    def __len__(self):\n",
        "        # Return the number of tracks in the dataset\n",
        "        return len(self.track_list)\n",
        "\n",
        "    def close(self):\n",
        "        # Close the HDF5 file if it is open\n",
        "        if hasattr(self, 'hdf5_file') and self.hdf5_file:\n",
        "            self.hdf5_file.close()\n",
        "\n",
        "    def __del__(self):\n",
        "        # Ensure the HDF5 file is closed when the object is deleted\n",
        "        self.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkZ_T70Jb-8M"
      },
      "source": [
        "Pads and collates a batch of data and targets to the maximum height and width in the batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCuEp-k0UmUp"
      },
      "outputs": [],
      "source": [
        "def pad_and_collate(batch):\n",
        "\n",
        "    # Find the maximum height and width in the batch for both data and targets\n",
        "    max_height = max(max(data.size(2), targets.size(2)) for data, targets in batch)\n",
        "    max_width = max(max(data.size(3), targets.size(3)) for data, targets in batch)\n",
        "\n",
        "    padded_batch = []\n",
        "    for data, targets in batch:\n",
        "        # Calculate the padding needed for the data tensor to match the maximum width and height\n",
        "        data_padding = (0, max_width - data.size(3), 0, max_height - data.size(2))\n",
        "        # Apply padding to the data tensor\n",
        "        padded_data = F.pad(data, data_padding, \"constant\", 0)\n",
        "\n",
        "        # Calculate the padding needed for the targets tensor to match the maximum width and height\n",
        "        target_padding = (0, max_width - targets.size(3), 0, max_height - targets.size(2))\n",
        "        # Apply padding to the targets tensor\n",
        "        padded_targets = F.pad(targets, target_padding, \"constant\", 0)\n",
        "\n",
        "        # Append the padded data and targets as a tuple to the padded batch\n",
        "        padded_batch.append((padded_data, padded_targets))\n",
        "\n",
        "    # Use the default collate function to convert the list of padded tuples into a batch tensor\n",
        "    return default_collate(padded_batch)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCe0WzgEcjjb"
      },
      "source": [
        "Retrieves a sorted list of unique track base names from an HDF5 file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "igyeELMWFf2X"
      },
      "outputs": [],
      "source": [
        "def get_unique_track_names(hdf5_path):\n",
        "    # Open the HDF5 file\n",
        "    with h5py.File(hdf5_path, 'r') as file:\n",
        "        # Retrieve keys from the HDF5 file\n",
        "        keys = list(file.keys())\n",
        "\n",
        "    # Extract base names by splitting each key\n",
        "    base_names = set(key.rsplit('_', 2)[0] for key in keys)\n",
        "\n",
        "    # Return the sorted list of unique base names\n",
        "    return sorted(base_names)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the spectrogram transformations with specified probabilities and parameters\n",
        "transform = SpectrogramTransforms(\n",
        "    p_time_mask=0.25,\n",
        "    p_freq_mask=0.25,\n",
        "    time_mask_param=20,\n",
        "    freq_mask_param=20,\n",
        "    time_stripes_num=3,\n",
        "    freq_stripes_num=3,\n",
        "    p_add_noise=0.25,\n",
        "    min_snr_db=10,\n",
        "    max_snr_db=20,\n",
        "    p_time_warp=0.3,\n",
        "    time_warp_param=80\n",
        ")\n",
        "\n",
        "\n",
        "# Define the path to the HDF5 file\n",
        "hdf5_path = '/content/drive/MyDrive/musdb18/custom_spectrograms_hdf5'\n",
        "\n",
        "# Get the list of unique track base names from the HDF5 file\n",
        "track_names = get_unique_track_names(hdf5_path)\n",
        "\n",
        "# Determine the total number of tracks to use\n",
        "total_tracks = min(100, len(track_names))  # Reduce for testing\n",
        "\n",
        "# Generate a list of indices for the tracks and shuffle them\n",
        "indices = list(range(total_tracks))\n",
        "random.shuffle(indices)\n",
        "\n",
        "# Split the indices into training and validation sets\n",
        "split_ratio = 0.9\n",
        "split_idx = int(max(1, total_tracks * split_ratio))\n",
        "train_track_names = [track_names[i] for i in indices[:split_idx]]\n",
        "valid_track_names = [track_names[i] for i in indices[split_idx:]]\n",
        "\n",
        "# Create training and validation datasets with the corresponding track names and transformations\n",
        "train_dataset = AudioDataset(hdf5_path=hdf5_path, track_list=train_track_names, transform=None)  # Disable transform for testing\n",
        "valid_dataset = AudioDataset(hdf5_path=hdf5_path, track_list=valid_track_names)\n",
        "\n",
        "# Set the batch size for data loading\n",
        "batch_size = 6  # Reduce batch size for testing\n",
        "\n",
        "# Create DataLoader for the training dataset\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=0,\n",
        "    pin_memory=True,\n",
        "    collate_fn=pad_and_collate\n",
        ")\n",
        "\n",
        "# Create DataLoader for the validation dataset\n",
        "valid_loader = DataLoader(\n",
        "    valid_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        "    pin_memory=True,\n",
        "    collate_fn=pad_and_collate\n",
        ")"
      ],
      "metadata": {
        "id": "DH3L0vYtYOKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L92s29qBDM6-"
      },
      "outputs": [],
      "source": [
        "#Initializes the weights of convolutional and transposed convolutional layers using Kaiming normal initialization, and initializes biases to zero.\n",
        "def init_weights(m):\n",
        "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
        "        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "        if m.bias is not None:\n",
        "            nn.init.constant_(m.bias, 0)\n",
        "\n",
        "#Initializes a complex convolutional block for real and imaginary channels.\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=(3, 3), padding=1, use_residual=True, dropout_prob=0.5):\n",
        "        super(ConvBlock, self).__init__()\n",
        "        self.use_residual = use_residual and in_channels == out_channels  # Use residual connections if specified and channels match\n",
        "        self.conv_real = nn.Conv2d(in_channels // 2, out_channels // 2, kernel_size, padding=padding)  # Real part convolution\n",
        "        self.conv_imag = nn.Conv2d(in_channels // 2, out_channels // 2, kernel_size, padding=padding)  # Imaginary part convolution\n",
        "        self.bn = nn.BatchNorm2d(out_channels)  # Batch normalization\n",
        "        self.dropout = nn.Dropout2d(dropout_prob)  # Dropout for regularization\n",
        "        self.conv_real.apply(init_weights)  # Initialize weights for real part convolution\n",
        "        self.conv_imag.apply(init_weights)  # Initialize weights for imaginary part convolution\n",
        "\n",
        "    #Defines forward pass for the convolutional block.\n",
        "    def forward(self, x):\n",
        "        real = x[:, :x.shape[1]//2, :, :]  # Split input tensor into real part\n",
        "        imag = x[:, x.shape[1]//2:, :, :]  # Split input tensor into imaginary part\n",
        "        real_updated = self.conv_real(real) - self.conv_imag(imag)  # Apply convolution and combine real and imaginary parts\n",
        "        imag_updated = self.conv_imag(real) + self.conv_real(imag)  # Apply convolution and combine real and imaginary parts\n",
        "        x_updated = torch.cat((real_updated, imag_updated), dim=1)  # Concatenate real and imaginary parts\n",
        "        x_updated = self.bn(x_updated)  # Apply batch normalization\n",
        "        x_updated = self.dropout(x_updated)  # Apply dropout\n",
        "        if self.use_residual:  # Check if residual connections are used\n",
        "            x_updated += x  # Add input to output for residual connection\n",
        "        return F.leaky_relu(x_updated)  # Apply leaky ReLU activation\n",
        "\n",
        "#Initializes the encoder block.\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, num_blocks=3, dropout_prob=0.5):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.initial_conv = ConvBlock(in_channels, out_channels, dropout_prob=dropout_prob)  # Initial convolutional block\n",
        "        self.layers = nn.ModuleList([  # List of subsequent convolutional blocks\n",
        "            ConvBlock(out_channels, out_channels, dropout_prob=dropout_prob) for _ in range(num_blocks - 1)\n",
        "        ])\n",
        "        self.pool = nn.MaxPool2d((2, 2))  # Max pooling layer\n",
        "        self.apply(init_weights)  # Initialize weights for all layers\n",
        "\n",
        "    #Defines forward pass for the encoder block.\n",
        "    def forward(self, x):\n",
        "        x = self.initial_conv(x)  # Apply initial convolutional block\n",
        "        for layer in self.layers:  # Apply each subsequent convolutional block\n",
        "            x = layer(x)\n",
        "        x_pooled = self.pool(x)  # Apply max pooling\n",
        "        return x, x_pooled  # Return the feature maps and the pooled output\n",
        "\n",
        "#Initializes the decoder block.\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, in_channels, skip_channels, out_channels, num_blocks=2, dropout_prob=0.5):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.upconv = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=(2, 2), stride=(2, 2))  # Transposed convolutional layer\n",
        "        self.layers = nn.ModuleList([  # List of convolutional blocks\n",
        "            ConvBlock(out_channels + skip_channels, out_channels, dropout_prob=dropout_prob) if i == 0\n",
        "            else ConvBlock(out_channels, out_channels, dropout_prob=dropout_prob)\n",
        "            for i in range(num_blocks)\n",
        "        ])\n",
        "        self.apply(init_weights)  # Initialize weights for all layers\n",
        "\n",
        "    #Defines forward pass for the decoder block.\n",
        "    def forward(self, x, skip):\n",
        "        x = self.upconv(x)  # Apply transposed convolution to upsample\n",
        "        if x.size()[2:] != skip.size()[2:]:  # If the sizes don't match\n",
        "            x = F.interpolate(x, size=skip.size()[2:], mode='nearest')  # Resize using nearest neighbor interpolation\n",
        "        x = torch.cat([x, skip], dim=1)  # Concatenate with the skip connection\n",
        "        for layer in self.layers:  # Apply each convolutional block\n",
        "            x = layer(x)\n",
        "        return x  # Return the output\n",
        "\n",
        "#Initializes the U-Net model with encoder and decoder blocks, and a final convolutional layer.\n",
        "class EnhancedUNet(nn.Module):\n",
        "    def __init__(self, in_channels=2, num_sources=4, dropout_prob=0.5):\n",
        "        super(EnhancedUNet, self).__init__()\n",
        "        self.enc1 = Encoder(in_channels, 64, dropout_prob=dropout_prob)\n",
        "        self.enc2 = Encoder(64, 128, dropout_prob=dropout_prob)\n",
        "        self.enc3 = Encoder(128, 256, dropout_prob=dropout_prob)\n",
        "        self.bottleneck = ConvBlock(256, 512, dropout_prob=dropout_prob)\n",
        "        self.dec3 = Decoder(512, 256, 256, dropout_prob=dropout_prob)\n",
        "        self.dec2 = Decoder(256, 128, 128, dropout_prob=dropout_prob)\n",
        "        self.dec1 = Decoder(128, 64, 64, dropout_prob=dropout_prob)\n",
        "        self.final_conv = nn.Conv2d(64, num_sources * 2, kernel_size=(1, 1))\n",
        "        self.apply(init_weights)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward pass through the encoder\n",
        "        x1, x = self.enc1(x)\n",
        "        x2, x = self.enc2(x)\n",
        "        x3, x = self.enc3(x)\n",
        "\n",
        "\n",
        "        # Bottleneck\n",
        "        x = self.bottleneck(x)\n",
        "\n",
        "        # Forward pass through the decoder\n",
        "\n",
        "        x = self.dec3(x, x3)\n",
        "        x = self.dec2(x, x2)\n",
        "        x = self.dec1(x, x1)\n",
        "\n",
        "        # Final convolution to match the number of output channels\n",
        "        x = self.final_conv(x)\n",
        "\n",
        "        # Reshape the output to have separate dimensions for sources and real/imaginary parts\n",
        "        x = x.view(x.size(0), 4, 2, x.size(2), x.size(3))\n",
        "\n",
        "        return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7d28vbihWtpr"
      },
      "outputs": [],
      "source": [
        "# Computes the L1 loss between the high-pass filtered versions of the output and target.\n",
        "def high_pass_filter_loss(output, target, cutoff_freq=3000, sample_rate=22050, epsilon=1e-8):\n",
        "    # Apply high-pass filter to the output and target\n",
        "    high_pass_output = torchaudio.functional.highpass_biquad(output + epsilon, sample_rate, cutoff_freq)\n",
        "    high_pass_target = torchaudio.functional.highpass_biquad(target + epsilon, sample_rate, cutoff_freq)\n",
        "    # Compute L1 loss between the filtered outputs\n",
        "    loss = F.l1_loss(high_pass_output, high_pass_target)\n",
        "    return loss\n",
        "\n",
        "# Computes the mean squared error (MSE) loss between the phases of the output and target.\n",
        "def phase_loss(output, target, epsilon=1e-8):\n",
        "    if output.shape == target.shape:\n",
        "        # Compute phase angles of the output and target\n",
        "        phase_output = torch.angle(output + epsilon)\n",
        "        phase_target = torch.angle(target + epsilon)\n",
        "        # Compute mean squared error loss between the phase angles\n",
        "        loss = F.mse_loss(phase_output, phase_target)\n",
        "    else:\n",
        "        # Return a small loss value if shapes do not match\n",
        "        loss = torch.tensor(epsilon, device=output.device)\n",
        "    return loss\n",
        "\n",
        "# Computes the spectral convergence loss between the output and target.\n",
        "def spectral_convergence_loss(output, target, epsilon=1e-8):\n",
        "    # Compute Frobenius norms of the target and difference between target and output\n",
        "    norm_target = torch.norm(target, p='fro', dim=[-2, -1]) + epsilon\n",
        "    norm_diff = torch.norm(target - output, p='fro', dim=[-2, -1])\n",
        "    # Compute spectral convergence loss\n",
        "    loss = norm_diff / norm_target\n",
        "    # Mask loss values for non-zero targets\n",
        "    mask = torch.any(target != 0, dim=[-2, -1])\n",
        "    masked_loss = loss * mask.to(loss.dtype)\n",
        "    # Compute normalized loss\n",
        "    if mask.any():\n",
        "        normalized_loss = masked_loss.sum() / mask.sum()\n",
        "    else:\n",
        "        normalized_loss = torch.tensor(0.0, device=loss.device).float()\n",
        "    return normalized_loss\n",
        "\n",
        "# Computes the L1 loss between the magnitudes of the output and target.\n",
        "def magnitude_loss(output, target):\n",
        "    # Compute magnitudes of the output and target\n",
        "    mag_output = torch.abs(output)\n",
        "    mag_target = torch.abs(target)\n",
        "    # Compute L1 loss between the magnitudes\n",
        "    loss = F.l1_loss(mag_output, mag_target)\n",
        "    return loss\n",
        "\n",
        "# Computes the mean squared error loss for interference between sources.\n",
        "def interference_loss(outputs, targets, epsilon=1e-8):\n",
        "    # Get the dimensions of the outputs tensor\n",
        "    batch_size, num_sources, freq_bins, time_frames = outputs.shape\n",
        "    # Initialize the total interference loss to zero\n",
        "    total_interference_loss = torch.tensor(0.0, device=outputs.device)\n",
        "\n",
        "    # Iterate over each source pair\n",
        "    for i in range(num_sources):\n",
        "        for j in range(num_sources):\n",
        "            if i != j:  # Skip if both indices are the same\n",
        "                # Calculate the absolute difference between the predicted and ground truth spectrograms\n",
        "                interference = torch.abs(outputs[:, i] - targets[:, j])\n",
        "                # Check if the interference tensor is empty\n",
        "                if interference.numel() == 0:\n",
        "                    print(f\"Empty interference tensor for sources {i} and {j}\")\n",
        "                    return None\n",
        "\n",
        "                # Calculate the mean squared error loss without reduction\n",
        "                interference_loss = F.mse_loss(interference, torch.zeros_like(interference), reduction='none')\n",
        "                # Sum the loss over the frequency and time dimensions\n",
        "                interference_loss = interference_loss.sum(dim=(1, 2))\n",
        "                # Normalize the loss by the number of frequency bins and time frames\n",
        "                interference_loss = interference_loss / (freq_bins * time_frames + epsilon)\n",
        "                # Add the mean interference loss to the total interference loss\n",
        "                total_interference_loss += interference_loss.mean()\n",
        "\n",
        "    # Average the total interference loss over the batch size\n",
        "    total_interference_loss /= batch_size\n",
        "\n",
        "    # Return the total interference loss if it's not empty, otherwise return None\n",
        "    return total_interference_loss if total_interference_loss.numel() != 0 else None\n",
        "\n",
        "# Computes a custom loss as a weighted sum of different loss components.\n",
        "def custom_loss(outputs, targets, weights, sample_rate=22050, cutoff_freq=3000, epsilon=1e-8):\n",
        "    # Extract weights for different loss components\n",
        "    spec_weight = weights['spec_weight']\n",
        "    mag_weight = weights['mag_weight']\n",
        "    phase_weight = weights['phase_weight']\n",
        "    interference_weight = weights['interference_weight']\n",
        "    artifacts_weight = weights['artifacts_weight']\n",
        "\n",
        "    # Initialize total loss\n",
        "    total_loss = torch.tensor(0.0, device=outputs.device)\n",
        "    for output, target in zip(outputs, targets):\n",
        "\n",
        "        # Compute individual loss components\n",
        "        spec_loss = spectral_convergence_loss(output, target)\n",
        "        mag_loss = magnitude_loss(output, target)\n",
        "        phs_loss = phase_loss(output, target)\n",
        "        intr_loss = interference_loss(output, target)\n",
        "        art_loss = high_pass_filter_loss(output, target, cutoff_freq=cutoff_freq, sample_rate=sample_rate)\n",
        "\n",
        "        # Ensure loss values are tensors\n",
        "        spec_loss = spec_loss if torch.is_tensor(spec_loss) else torch.tensor(spec_loss, device=outputs.device)\n",
        "        mag_loss = mag_loss if torch.is_tensor(mag_loss) else torch.tensor(mag_loss, device=outputs.device)\n",
        "        phs_loss = phs_loss if torch.is_tensor(phs_loss) else torch.tensor(phs_loss, device=outputs.device)\n",
        "        intr_loss = intr_loss if torch.is_tensor(intr_loss) else torch.tensor(intr_loss, device=outputs.device)\n",
        "        art_loss = art_loss if torch.is_tensor(art_loss) else torch.tensor(art_loss, device=outputs.device)\n",
        "\n",
        "        # Ensure phase loss is non-zero\n",
        "        if phs_loss == 0.0:\n",
        "            phs_loss = torch.tensor(epsilon, device=outputs.device)\n",
        "\n",
        "        # Sum weighted loss components to total loss\n",
        "        total_loss += (spec_weight * spec_loss + mag_weight * mag_loss + phase_weight * phs_loss +\n",
        "                       interference_weight * intr_loss + artifacts_weight * art_loss)\n",
        "\n",
        "    # Compute and return average loss\n",
        "    average_loss = total_loss / len(outputs)\n",
        "    return average_loss\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjfOrMj5SR9R"
      },
      "outputs": [],
      "source": [
        "# Normalizes the weights such that their sum is equal to 1.\n",
        "def normalize_weights(weights):\n",
        "    # Calculate the combined value of all weights\n",
        "    total_weight = sum(weights.values())\n",
        "    # Divide each weight by the total sum to normalize them\n",
        "    return {k: v / total_weight for k, v in weights.items()}\n",
        "\n",
        "# Updates the weights based on performance metrics and normalizes them.\n",
        "def update_weights(weights, metrics, loss_metric_mapping, threshold=0.01, adjustment_factor=1.1):\n",
        "    new_weights = weights.copy()  # Create a copy of the current weights\n",
        "    for loss_key, metric_key in loss_metric_mapping.items():\n",
        "        # Get the latest metric value for the corresponding metric\n",
        "        current_metric_value = metrics[metric_key][-1]\n",
        "        if current_metric_value < threshold:  # If the metric value is below the threshold\n",
        "            new_weights[loss_key] *= adjustment_factor  # Increase the weight\n",
        "        else:\n",
        "            new_weights[loss_key] /= adjustment_factor  # Decrease the weight\n",
        "\n",
        "    new_weights = normalize_weights(new_weights)  # Normalize the updated weights\n",
        "\n",
        "    return new_weights  # Return the updated and normalized weights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BuKJ-tpJDH8N"
      },
      "outputs": [],
      "source": [
        "# Inspects the dimensions of the input tensor and prepares it by permuting and reshaping as needed.\n",
        "def inspect_and_prepare_data(tensor, is_target=False):\n",
        "  if tensor.dim() == 5:  # If the tensor has 5 dimensions\n",
        "        if is_target:\n",
        "            # Permute dimensions for target tensor to match the required shape\n",
        "            tensor = tensor.permute(0, 1, 4, 2, 3)\n",
        "        else:\n",
        "            # Permute and reshape dimensions for input tensor\n",
        "            tensor = tensor.permute(0, 1, 4, 2, 3).reshape(-1, tensor.shape[4], tensor.shape[2], tensor.shape[3])\n",
        "  elif tensor.dim() == 4:  # If the tensor has 4 dimensions\n",
        "      if tensor.size(1) < tensor.size(3):\n",
        "          # Permute dimensions if the second dimension is smaller than the last dimension\n",
        "          tensor = tensor.permute(0, 3, 1, 2)\n",
        "  else:\n",
        "      # Raise an error if the tensor has an unexpected number of dimensions\n",
        "      raise ValueError(f\"Unexpected number of dimensions: {tensor.dim()}\")\n",
        "\n",
        "  return tensor  # Return the prepared tensor\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDv4ltr64HT5"
      },
      "source": [
        "The `invert_spectrogram` function takes a complex spectrogram and transforms it back to an audio signal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5jTeFBWtmz_a"
      },
      "outputs": [],
      "source": [
        "def invert_spectrogram(complex_spec, n_fft=1024, hop_length=512, device='cpu'):\n",
        "    # Squeeze the last dimension if it is 1 (refering to # of sources)\n",
        "    if complex_spec.shape[-1] == 1:\n",
        "        complex_spec = complex_spec.squeeze(-1)\n",
        "\n",
        "    # Permute dimensions if the first dimension is 2 (refering to # of channels)\n",
        "    if complex_spec.shape[0] == 2:\n",
        "        complex_spec = complex_spec.permute(1, 2, 0)\n",
        "\n",
        "    # Ensure the tensor is contiguous in memory\n",
        "    complex_spec = complex_spec.contiguous()\n",
        "\n",
        "    # Convert to complex tensor if not already complex\n",
        "    if not torch.is_complex(complex_spec):\n",
        "        complex_spec = torch.view_as_complex(complex_spec)\n",
        "\n",
        "    # Calculate the length of the output audio signal\n",
        "    length = (complex_spec.size(1) - 1) * hop_length\n",
        "\n",
        "    # Return a tensor of zeros if the maximum absolute value of the spectrogram is very small\n",
        "    if complex_spec.abs().max().item() < 1e-8:\n",
        "        return torch.zeros((length), device=device)\n",
        "\n",
        "    # Create a Hann window for the inverse Short-Time Fourier Transform (STFT)\n",
        "    window = torch.hann_window(n_fft, device=device)\n",
        "\n",
        "    # Perform the inverse STFT to get the time-domain audio signal\n",
        "    audio = torch.istft(complex_spec, n_fft=n_fft, hop_length=hop_length, window=window, length=length)\n",
        "    return audio  # Return the reconstructed audio signal\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "toFYnnJkX5do",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d1d57b28-0daa-4ea0-81be-369ab8c3d946"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1        [-1, 32, 513, 1292]             320\n",
            "            Conv2d-2        [-1, 32, 513, 1292]             320\n",
            "            Conv2d-3        [-1, 32, 513, 1292]             320\n",
            "            Conv2d-4        [-1, 32, 513, 1292]             320\n",
            "       BatchNorm2d-5        [-1, 64, 513, 1292]             128\n",
            "         Dropout2d-6        [-1, 64, 513, 1292]               0\n",
            "         ConvBlock-7        [-1, 64, 513, 1292]               0\n",
            "            Conv2d-8        [-1, 32, 513, 1292]           9,248\n",
            "            Conv2d-9        [-1, 32, 513, 1292]           9,248\n",
            "           Conv2d-10        [-1, 32, 513, 1292]           9,248\n",
            "           Conv2d-11        [-1, 32, 513, 1292]           9,248\n",
            "      BatchNorm2d-12        [-1, 64, 513, 1292]             128\n",
            "        Dropout2d-13        [-1, 64, 513, 1292]               0\n",
            "        ConvBlock-14        [-1, 64, 513, 1292]               0\n",
            "           Conv2d-15        [-1, 32, 513, 1292]           9,248\n",
            "           Conv2d-16        [-1, 32, 513, 1292]           9,248\n",
            "           Conv2d-17        [-1, 32, 513, 1292]           9,248\n",
            "           Conv2d-18        [-1, 32, 513, 1292]           9,248\n",
            "      BatchNorm2d-19        [-1, 64, 513, 1292]             128\n",
            "        Dropout2d-20        [-1, 64, 513, 1292]               0\n",
            "        ConvBlock-21        [-1, 64, 513, 1292]               0\n",
            "        MaxPool2d-22         [-1, 64, 256, 646]               0\n",
            "          Encoder-23  [[-1, 64, 513, 1292], [-1, 64, 256, 646]]               0\n",
            "           Conv2d-24         [-1, 64, 256, 646]          18,496\n",
            "           Conv2d-25         [-1, 64, 256, 646]          18,496\n",
            "           Conv2d-26         [-1, 64, 256, 646]          18,496\n",
            "           Conv2d-27         [-1, 64, 256, 646]          18,496\n",
            "      BatchNorm2d-28        [-1, 128, 256, 646]             256\n",
            "        Dropout2d-29        [-1, 128, 256, 646]               0\n",
            "        ConvBlock-30        [-1, 128, 256, 646]               0\n",
            "           Conv2d-31         [-1, 64, 256, 646]          36,928\n",
            "           Conv2d-32         [-1, 64, 256, 646]          36,928\n",
            "           Conv2d-33         [-1, 64, 256, 646]          36,928\n",
            "           Conv2d-34         [-1, 64, 256, 646]          36,928\n",
            "      BatchNorm2d-35        [-1, 128, 256, 646]             256\n",
            "        Dropout2d-36        [-1, 128, 256, 646]               0\n",
            "        ConvBlock-37        [-1, 128, 256, 646]               0\n",
            "           Conv2d-38         [-1, 64, 256, 646]          36,928\n",
            "           Conv2d-39         [-1, 64, 256, 646]          36,928\n",
            "           Conv2d-40         [-1, 64, 256, 646]          36,928\n",
            "           Conv2d-41         [-1, 64, 256, 646]          36,928\n",
            "      BatchNorm2d-42        [-1, 128, 256, 646]             256\n",
            "        Dropout2d-43        [-1, 128, 256, 646]               0\n",
            "        ConvBlock-44        [-1, 128, 256, 646]               0\n",
            "        MaxPool2d-45        [-1, 128, 128, 323]               0\n",
            "          Encoder-46  [[-1, 128, 256, 646], [-1, 128, 128, 323]]               0\n",
            "           Conv2d-47        [-1, 128, 128, 323]          73,856\n",
            "           Conv2d-48        [-1, 128, 128, 323]          73,856\n",
            "           Conv2d-49        [-1, 128, 128, 323]          73,856\n",
            "           Conv2d-50        [-1, 128, 128, 323]          73,856\n",
            "      BatchNorm2d-51        [-1, 256, 128, 323]             512\n",
            "        Dropout2d-52        [-1, 256, 128, 323]               0\n",
            "        ConvBlock-53        [-1, 256, 128, 323]               0\n",
            "           Conv2d-54        [-1, 128, 128, 323]         147,584\n",
            "           Conv2d-55        [-1, 128, 128, 323]         147,584\n",
            "           Conv2d-56        [-1, 128, 128, 323]         147,584\n",
            "           Conv2d-57        [-1, 128, 128, 323]         147,584\n",
            "      BatchNorm2d-58        [-1, 256, 128, 323]             512\n",
            "        Dropout2d-59        [-1, 256, 128, 323]               0\n",
            "        ConvBlock-60        [-1, 256, 128, 323]               0\n",
            "           Conv2d-61        [-1, 128, 128, 323]         147,584\n",
            "           Conv2d-62        [-1, 128, 128, 323]         147,584\n",
            "           Conv2d-63        [-1, 128, 128, 323]         147,584\n",
            "           Conv2d-64        [-1, 128, 128, 323]         147,584\n",
            "      BatchNorm2d-65        [-1, 256, 128, 323]             512\n",
            "        Dropout2d-66        [-1, 256, 128, 323]               0\n",
            "        ConvBlock-67        [-1, 256, 128, 323]               0\n",
            "        MaxPool2d-68         [-1, 256, 64, 161]               0\n",
            "          Encoder-69  [[-1, 256, 128, 323], [-1, 256, 64, 161]]               0\n",
            "           Conv2d-70         [-1, 256, 64, 161]         295,168\n",
            "           Conv2d-71         [-1, 256, 64, 161]         295,168\n",
            "           Conv2d-72         [-1, 256, 64, 161]         295,168\n",
            "           Conv2d-73         [-1, 256, 64, 161]         295,168\n",
            "      BatchNorm2d-74         [-1, 512, 64, 161]           1,024\n",
            "        Dropout2d-75         [-1, 512, 64, 161]               0\n",
            "        ConvBlock-76         [-1, 512, 64, 161]               0\n",
            "  ConvTranspose2d-77        [-1, 256, 128, 322]         524,544\n",
            "           Conv2d-78        [-1, 128, 128, 323]         295,040\n",
            "           Conv2d-79        [-1, 128, 128, 323]         295,040\n",
            "           Conv2d-80        [-1, 128, 128, 323]         295,040\n",
            "           Conv2d-81        [-1, 128, 128, 323]         295,040\n",
            "      BatchNorm2d-82        [-1, 256, 128, 323]             512\n",
            "        Dropout2d-83        [-1, 256, 128, 323]               0\n",
            "        ConvBlock-84        [-1, 256, 128, 323]               0\n",
            "           Conv2d-85        [-1, 128, 128, 323]         147,584\n",
            "           Conv2d-86        [-1, 128, 128, 323]         147,584\n",
            "           Conv2d-87        [-1, 128, 128, 323]         147,584\n",
            "           Conv2d-88        [-1, 128, 128, 323]         147,584\n",
            "      BatchNorm2d-89        [-1, 256, 128, 323]             512\n",
            "        Dropout2d-90        [-1, 256, 128, 323]               0\n",
            "        ConvBlock-91        [-1, 256, 128, 323]               0\n",
            "          Decoder-92        [-1, 256, 128, 323]               0\n",
            "  ConvTranspose2d-93        [-1, 128, 256, 646]         131,200\n",
            "           Conv2d-94         [-1, 64, 256, 646]          73,792\n",
            "           Conv2d-95         [-1, 64, 256, 646]          73,792\n",
            "           Conv2d-96         [-1, 64, 256, 646]          73,792\n",
            "           Conv2d-97         [-1, 64, 256, 646]          73,792\n",
            "      BatchNorm2d-98        [-1, 128, 256, 646]             256\n",
            "        Dropout2d-99        [-1, 128, 256, 646]               0\n",
            "       ConvBlock-100        [-1, 128, 256, 646]               0\n",
            "          Conv2d-101         [-1, 64, 256, 646]          36,928\n",
            "          Conv2d-102         [-1, 64, 256, 646]          36,928\n",
            "          Conv2d-103         [-1, 64, 256, 646]          36,928\n",
            "          Conv2d-104         [-1, 64, 256, 646]          36,928\n",
            "     BatchNorm2d-105        [-1, 128, 256, 646]             256\n",
            "       Dropout2d-106        [-1, 128, 256, 646]               0\n",
            "       ConvBlock-107        [-1, 128, 256, 646]               0\n",
            "         Decoder-108        [-1, 128, 256, 646]               0\n",
            " ConvTranspose2d-109        [-1, 64, 512, 1292]          32,832\n",
            "          Conv2d-110        [-1, 32, 513, 1292]          18,464\n",
            "          Conv2d-111        [-1, 32, 513, 1292]          18,464\n",
            "          Conv2d-112        [-1, 32, 513, 1292]          18,464\n",
            "          Conv2d-113        [-1, 32, 513, 1292]          18,464\n",
            "     BatchNorm2d-114        [-1, 64, 513, 1292]             128\n",
            "       Dropout2d-115        [-1, 64, 513, 1292]               0\n",
            "       ConvBlock-116        [-1, 64, 513, 1292]               0\n",
            "          Conv2d-117        [-1, 32, 513, 1292]           9,248\n",
            "          Conv2d-118        [-1, 32, 513, 1292]           9,248\n",
            "          Conv2d-119        [-1, 32, 513, 1292]           9,248\n",
            "          Conv2d-120        [-1, 32, 513, 1292]           9,248\n",
            "     BatchNorm2d-121        [-1, 64, 513, 1292]             128\n",
            "       Dropout2d-122        [-1, 64, 513, 1292]               0\n",
            "       ConvBlock-123        [-1, 64, 513, 1292]               0\n",
            "         Decoder-124        [-1, 64, 513, 1292]               0\n",
            "          Conv2d-125         [-1, 8, 513, 1292]             520\n",
            "================================================================\n",
            "Total params: 6,120,264\n",
            "Trainable params: 6,120,264\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 5.06\n",
            "Forward/backward pass size (MB): 4492981523.14\n",
            "Params size (MB): 23.35\n",
            "Estimated Total Size (MB): 4492981551.55\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/300, Average Training Loss: 6.8701\n",
            "Validation Loss: 2.6013\n",
            "Epoch 2/300, Average Training Loss: 5.6539\n",
            "Validation Loss: 2.4803\n",
            "Epoch 3/300, Average Training Loss: 4.7718\n",
            "Validation Loss: 2.2162\n",
            "Epoch 4/300, Average Training Loss: 4.2598\n",
            "Validation Loss: 2.1187\n",
            "Epoch 5/300, Average Training Loss: 3.7298\n",
            "Validation Loss: 1.8936\n",
            "Epoch 6/300, Average Training Loss: 3.3328\n",
            "Validation Loss: 1.5961\n",
            "Epoch 7/300, Average Training Loss: 2.9566\n",
            "Validation Loss: 1.4629\n",
            "Epoch 8/300, Average Training Loss: 2.8631\n",
            "Validation Loss: 1.4255\n",
            "Epoch 9/300, Average Training Loss: 2.6306\n",
            "Validation Loss: 1.3606\n",
            "Epoch 10/300, Average Training Loss: 2.5278\n",
            "Training Metrics after 10 epochs - SDR: -7.77, SIR: -6.71, SAR: -13.39, ISR: -4.91\n",
            "Validation Loss: 1.3638\n",
            "Epoch 11/300, Average Training Loss: 2.4864\n",
            "Validation Loss: 1.3429\n",
            "Epoch 12/300, Average Training Loss: 2.3119\n",
            "Validation Loss: 1.3011\n",
            "Epoch 13/300, Average Training Loss: 2.3868\n",
            "Validation Loss: 1.3244\n",
            "Epoch 14/300, Average Training Loss: 2.3706\n",
            "Validation Loss: 1.3079\n",
            "Epoch 15/300, Average Training Loss: 2.1932\n",
            "Validation Loss: 1.2698\n",
            "Epoch 16/300, Average Training Loss: 2.2054\n",
            "Validation Loss: 1.2734\n",
            "Epoch 17/300, Average Training Loss: 2.2074\n",
            "Validation Loss: 1.2701\n",
            "Epoch 18/300, Average Training Loss: 2.0869\n",
            "Validation Loss: 1.2631\n",
            "Epoch 19/300, Average Training Loss: 2.0123\n",
            "Validation Loss: 1.2506\n",
            "Epoch 20/300, Average Training Loss: 2.0706\n",
            "Training Metrics after 20 epochs - SDR: -6.71, SIR: -6.49, SAR: -12.97, ISR: -4.49\n",
            "Validation Loss: 1.2671\n",
            "Epoch 21/300, Average Training Loss: 2.0499\n",
            "Validation Loss: 1.2835\n",
            "Epoch 22/300, Average Training Loss: 2.0490\n",
            "Validation Loss: 1.2333\n",
            "Epoch 23/300, Average Training Loss: 1.8709\n",
            "Validation Loss: 1.2172\n",
            "Epoch 24/300, Average Training Loss: 1.9888\n",
            "Validation Loss: 1.2238\n",
            "Epoch 25/300, Average Training Loss: 1.9423\n",
            "Validation Loss: 1.2187\n",
            "Epoch 26/300, Average Training Loss: 1.8673\n",
            "Validation Loss: 1.2207\n",
            "Epoch 27/300, Average Training Loss: 1.9435\n",
            "Validation Loss: 1.2424\n",
            "Epoch 28/300, Average Training Loss: 1.8435\n",
            "Validation Loss: 1.2272\n",
            "Epoch 29/300, Average Training Loss: 1.9497\n",
            "Validation Loss: 1.2456\n",
            "Epoch 30/300, Average Training Loss: 1.8668\n",
            "Training Metrics after 30 epochs - SDR: -6.43, SIR: -6.07, SAR: -11.84, ISR: -4.41\n",
            "Validation Loss: 1.2331\n",
            "Epoch 31/300, Average Training Loss: 1.8980\n",
            "Validation Loss: 1.2368\n",
            "Epoch 32/300, Average Training Loss: 1.7786\n",
            "Validation Loss: 1.2266\n",
            "Epoch 33/300, Average Training Loss: 1.8296\n",
            "Validation Loss: 1.2332\n",
            "Epoch 34/300, Average Training Loss: 1.8122\n",
            "Validation Loss: 1.2429\n",
            "Epoch 35/300, Average Training Loss: 1.7913\n",
            "Validation Loss: 1.2264\n",
            "Epoch 36/300, Average Training Loss: 1.8202\n",
            "Validation Loss: 1.2073\n",
            "Epoch 37/300, Average Training Loss: 1.7793\n",
            "Validation Loss: 1.2104\n",
            "Epoch 38/300, Average Training Loss: 1.7916\n",
            "Validation Loss: 1.1989\n",
            "Epoch 39/300, Average Training Loss: 1.8723\n",
            "Validation Loss: 1.1907\n",
            "Epoch 40/300, Average Training Loss: 1.8557\n",
            "Training Metrics after 40 epochs - SDR: -6.26, SIR: -6.19, SAR: -10.20, ISR: -4.26\n",
            "Validation Loss: 1.1723\n",
            "Epoch 41/300, Average Training Loss: 1.7394\n",
            "Validation Loss: 1.1869\n",
            "Epoch 42/300, Average Training Loss: 1.7115\n",
            "Validation Loss: 1.1800\n",
            "Epoch 43/300, Average Training Loss: 1.6976\n",
            "Validation Loss: 1.1940\n",
            "Epoch 44/300, Average Training Loss: 1.6708\n",
            "Validation Loss: 1.1754\n",
            "Epoch 45/300, Average Training Loss: 1.7051\n",
            "Validation Loss: 1.1908\n",
            "Epoch 46/300, Average Training Loss: 1.8403\n",
            "Validation Loss: 1.2261\n",
            "Epoch 47/300, Average Training Loss: 1.7047\n",
            "Validation Loss: 1.1522\n",
            "Epoch 48/300, Average Training Loss: 1.6431\n",
            "Validation Loss: 1.1695\n",
            "Epoch 49/300, Average Training Loss: 1.7020\n",
            "Validation Loss: 1.2052\n",
            "Epoch 50/300, Average Training Loss: 1.7580\n",
            "Training Metrics after 50 epochs - SDR: -6.03, SIR: -6.10, SAR: -9.54, ISR: -4.25\n",
            "Validation Loss: 1.2035\n",
            "Epoch 51/300, Average Training Loss: 1.6586\n",
            "Validation Loss: 1.1747\n",
            "Epoch 52/300, Average Training Loss: 1.6833\n",
            "Validation Loss: 1.1645\n",
            "Epoch 53/300, Average Training Loss: 1.6921\n",
            "Validation Loss: 1.1612\n",
            "Epoch 54/300, Average Training Loss: 1.7258\n",
            "Validation Loss: 1.2023\n",
            "Epoch 55/300, Average Training Loss: 1.7113\n",
            "Validation Loss: 1.1956\n",
            "Epoch 56/300, Average Training Loss: 1.6432\n",
            "Validation Loss: 1.1731\n",
            "Epoch 57/300, Average Training Loss: 1.6262\n",
            "Validation Loss: 1.1685\n",
            "Epoch 58/300, Average Training Loss: 1.6345\n",
            "Validation Loss: 1.1898\n",
            "Epoch 59/300, Average Training Loss: 1.6564\n",
            "Validation Loss: 1.1902\n",
            "Epoch 60/300, Average Training Loss: 1.6714\n",
            "Training Metrics after 60 epochs - SDR: -5.79, SIR: -6.34, SAR: -7.76, ISR: -4.15\n",
            "Validation Loss: 1.1841\n",
            "Epoch 61/300, Average Training Loss: 1.6321\n",
            "Validation Loss: 1.2021\n",
            "Epoch 62/300, Average Training Loss: 1.5944\n",
            "Validation Loss: 1.1943\n",
            "Epoch 63/300, Average Training Loss: 1.6375\n",
            "Validation Loss: 1.2025\n",
            "Epoch 64/300, Average Training Loss: 1.5557\n",
            "Validation Loss: 1.2362\n",
            "Epoch 65/300, Average Training Loss: 1.6127\n",
            "Validation Loss: 1.2269\n",
            "Epoch 66/300, Average Training Loss: 1.6346\n",
            "Validation Loss: 1.1645\n",
            "Epoch 67/300, Average Training Loss: 1.6025\n",
            "Validation Loss: 1.2002\n",
            "Epoch 68/300, Average Training Loss: 1.6231\n",
            "Validation Loss: 1.1985\n",
            "Epoch 69/300, Average Training Loss: 1.6127\n",
            "Validation Loss: 1.1552\n",
            "Epoch 70/300, Average Training Loss: 1.5862\n",
            "Training Metrics after 70 epochs - SDR: -5.98, SIR: -6.54, SAR: -6.08, ISR: -4.26\n",
            "Validation Loss: 1.1392\n",
            "Epoch 71/300, Average Training Loss: 1.6077\n",
            "Validation Loss: 1.1500\n",
            "Epoch 72/300, Average Training Loss: 1.5939\n",
            "Validation Loss: 1.1937\n",
            "Epoch 73/300, Average Training Loss: 1.5382\n",
            "Validation Loss: 1.1918\n",
            "Epoch 74/300, Average Training Loss: 1.6059\n",
            "Validation Loss: 1.1963\n",
            "Epoch 75/300, Average Training Loss: 1.5796\n",
            "Validation Loss: 1.1861\n",
            "Epoch 76/300, Average Training Loss: 1.5977\n",
            "Validation Loss: 1.2357\n",
            "Epoch 77/300, Average Training Loss: 1.5393\n",
            "Validation Loss: 1.2138\n",
            "Epoch 78/300, Average Training Loss: 1.5435\n",
            "Validation Loss: 1.2146\n",
            "Epoch 79/300, Average Training Loss: 1.5488\n",
            "Validation Loss: 1.2116\n",
            "Epoch 80/300, Average Training Loss: 1.5362\n",
            "Training Metrics after 80 epochs - SDR: -5.50, SIR: -6.88, SAR: -6.46, ISR: -3.68\n",
            "Validation Loss: 1.2146\n",
            "Epoch 81/300, Average Training Loss: 1.5621\n",
            "Validation Loss: 1.2147\n",
            "Epoch 82/300, Average Training Loss: 1.5642\n",
            "Validation Loss: 1.2145\n",
            "Epoch 83/300, Average Training Loss: 1.5434\n",
            "Validation Loss: 1.2004\n",
            "Epoch 84/300, Average Training Loss: 1.5247\n",
            "Validation Loss: 1.2093\n",
            "Epoch 85/300, Average Training Loss: 1.5557\n",
            "Validation Loss: 1.1556\n",
            "Epoch 86/300, Average Training Loss: 1.5395\n",
            "Validation Loss: 1.1503\n",
            "Epoch 87/300, Average Training Loss: 1.5064\n",
            "Validation Loss: 1.1605\n",
            "Epoch 88/300, Average Training Loss: 1.5320\n",
            "Validation Loss: 1.1855\n",
            "Epoch 89/300, Average Training Loss: 1.5339\n",
            "Validation Loss: 1.1809\n",
            "Epoch 90/300, Average Training Loss: 1.5061\n",
            "Training Metrics after 90 epochs - SDR: -5.82, SIR: -6.75, SAR: -5.52, ISR: -4.18\n",
            "Validation Loss: 1.1869\n",
            "Epoch 91/300, Average Training Loss: 1.5442\n",
            "Validation Loss: 1.1683\n",
            "Epoch 92/300, Average Training Loss: 1.5339\n",
            "Validation Loss: 1.1789\n",
            "Epoch 93/300, Average Training Loss: 1.5022\n",
            "Validation Loss: 1.1938\n",
            "Epoch 94/300, Average Training Loss: 1.5131\n",
            "Validation Loss: 1.1932\n",
            "Epoch 95/300, Average Training Loss: 1.5484\n",
            "Validation Loss: 1.1821\n",
            "Epoch 96/300, Average Training Loss: 1.4937\n",
            "Validation Loss: 1.2007\n",
            "Epoch 97/300, Average Training Loss: 1.4889\n",
            "Validation Loss: 1.1967\n",
            "Epoch 98/300, Average Training Loss: 1.5143\n",
            "Validation Loss: 1.2067\n",
            "Epoch 99/300, Average Training Loss: 1.5316\n",
            "Validation Loss: 1.2200\n",
            "Epoch 100/300, Average Training Loss: 1.4924\n",
            "Training Metrics after 100 epochs - SDR: -5.83, SIR: -7.12, SAR: -4.22, ISR: -3.93\n",
            "Validation Loss: 1.2082\n",
            "Epoch 101/300, Average Training Loss: 1.5137\n",
            "Validation Loss: 1.2176\n",
            "Epoch 102/300, Average Training Loss: 1.4961\n",
            "Validation Loss: 1.2204\n",
            "Epoch 103/300, Average Training Loss: 1.5091\n",
            "Validation Loss: 1.2215\n",
            "Epoch 104/300, Average Training Loss: 1.5075\n",
            "Validation Loss: 1.2054\n",
            "Epoch 105/300, Average Training Loss: 1.4712\n",
            "Validation Loss: 1.2030\n",
            "Epoch 106/300, Average Training Loss: 1.4610\n",
            "Validation Loss: 1.2093\n",
            "Epoch 107/300, Average Training Loss: 1.4627\n",
            "Validation Loss: 1.2074\n",
            "Epoch 108/300, Average Training Loss: 1.4648\n",
            "Validation Loss: 1.2065\n",
            "Epoch 109/300, Average Training Loss: 1.4350\n",
            "Validation Loss: 1.2089\n",
            "Epoch 110/300, Average Training Loss: 1.4609\n",
            "Training Metrics after 110 epochs - SDR: -5.80, SIR: -7.66, SAR: -4.20, ISR: -3.60\n",
            "Validation Loss: 1.2057\n",
            "Epoch 111/300, Average Training Loss: 1.4307\n",
            "Validation Loss: 1.2055\n",
            "Epoch 112/300, Average Training Loss: 1.4342\n",
            "Validation Loss: 1.2010\n",
            "Epoch 113/300, Average Training Loss: 1.4088\n",
            "Validation Loss: 1.2061\n",
            "Epoch 114/300, Average Training Loss: 1.4298\n",
            "Validation Loss: 1.2033\n",
            "Epoch 115/300, Average Training Loss: 1.4170\n",
            "Validation Loss: 1.1986\n",
            "Epoch 116/300, Average Training Loss: 1.4448\n",
            "Validation Loss: 1.1981\n",
            "Epoch 117/300, Average Training Loss: 1.4064\n",
            "Validation Loss: 1.1998\n",
            "Epoch 118/300, Average Training Loss: 1.4183\n",
            "Validation Loss: 1.2030\n",
            "Epoch 119/300, Average Training Loss: 1.3918\n",
            "Validation Loss: 1.1957\n",
            "Epoch 120/300, Average Training Loss: 1.4261\n",
            "Training Metrics after 120 epochs - SDR: -5.81, SIR: -7.96, SAR: -3.63, ISR: -3.43\n",
            "Validation Loss: 1.2010\n",
            "Epoch 121/300, Average Training Loss: 1.4482\n",
            "Validation Loss: 1.2005\n",
            "Epoch 122/300, Average Training Loss: 1.3720\n",
            "Validation Loss: 1.1901\n",
            "Epoch 123/300, Average Training Loss: 1.4081\n",
            "Validation Loss: 1.1890\n",
            "Epoch 124/300, Average Training Loss: 1.3982\n",
            "Validation Loss: 1.1879\n",
            "Epoch 125/300, Average Training Loss: 1.4181\n",
            "Validation Loss: 1.1867\n",
            "Epoch 126/300, Average Training Loss: 1.4283\n",
            "Validation Loss: 1.2125\n",
            "Epoch 127/300, Average Training Loss: 1.4664\n",
            "Validation Loss: 1.1902\n",
            "Epoch 128/300, Average Training Loss: 1.3893\n",
            "Validation Loss: 1.1941\n",
            "Epoch 129/300, Average Training Loss: 1.4087\n",
            "Validation Loss: 1.1952\n",
            "Epoch 130/300, Average Training Loss: 1.3948\n",
            "Training Metrics after 130 epochs - SDR: -5.91, SIR: -7.89, SAR: -3.20, ISR: -3.53\n",
            "Validation Loss: 1.1923\n",
            "Epoch 131/300, Average Training Loss: 1.3758\n",
            "Validation Loss: 1.1909\n",
            "Epoch 132/300, Average Training Loss: 1.3793\n",
            "Validation Loss: 1.1964\n",
            "Epoch 133/300, Average Training Loss: 1.3863\n",
            "Validation Loss: 1.1928\n",
            "Epoch 134/300, Average Training Loss: 1.3805\n",
            "Validation Loss: 1.1959\n",
            "Epoch 135/300, Average Training Loss: 1.3877\n",
            "Validation Loss: 1.2022\n",
            "Epoch 136/300, Average Training Loss: 1.3913\n",
            "Validation Loss: 1.2153\n",
            "Epoch 137/300, Average Training Loss: 1.4196\n",
            "Validation Loss: 1.2149\n",
            "Epoch 138/300, Average Training Loss: 1.3759\n",
            "Validation Loss: 1.2120\n",
            "Epoch 139/300, Average Training Loss: 1.4344\n",
            "Validation Loss: 1.2126\n",
            "Epoch 140/300, Average Training Loss: 1.3851\n",
            "Training Metrics after 140 epochs - SDR: -5.90, SIR: -8.13, SAR: -2.24, ISR: -3.31\n",
            "Validation Loss: 1.2123\n",
            "Epoch 141/300, Average Training Loss: 1.4083\n",
            "Validation Loss: 1.2101\n",
            "Epoch 142/300, Average Training Loss: 1.3953\n",
            "Validation Loss: 1.2080\n",
            "Epoch 143/300, Average Training Loss: 1.3775\n",
            "Validation Loss: 1.2065\n",
            "Epoch 144/300, Average Training Loss: 1.3964\n",
            "Validation Loss: 1.1925\n",
            "Epoch 145/300, Average Training Loss: 1.3341\n",
            "Validation Loss: 1.2007\n",
            "Epoch 146/300, Average Training Loss: 1.3722\n",
            "Validation Loss: 1.1797\n",
            "Epoch 147/300, Average Training Loss: 1.3483\n",
            "Validation Loss: 1.2137\n",
            "Epoch 148/300, Average Training Loss: 1.3972\n",
            "Validation Loss: 1.2117\n",
            "Epoch 149/300, Average Training Loss: 1.4064\n",
            "Validation Loss: 1.2249\n",
            "Epoch 150/300, Average Training Loss: 1.3678\n",
            "Training Metrics after 150 epochs - SDR: -5.89, SIR: -7.89, SAR: -0.44, ISR: -3.19\n",
            "Validation Loss: 1.2099\n",
            "Epoch 151/300, Average Training Loss: 1.4040\n",
            "Validation Loss: 1.2264\n",
            "Epoch 152/300, Average Training Loss: 1.3961\n",
            "Validation Loss: 1.2433\n",
            "Epoch 153/300, Average Training Loss: 1.3799\n",
            "Validation Loss: 1.2539\n",
            "Epoch 154/300, Average Training Loss: 1.4079\n",
            "Validation Loss: 1.2519\n",
            "Epoch 155/300, Average Training Loss: 1.3751\n",
            "Validation Loss: 1.2520\n",
            "Epoch 156/300, Average Training Loss: 1.3989\n",
            "Validation Loss: 1.2551\n",
            "Epoch 157/300, Average Training Loss: 1.4001\n",
            "Validation Loss: 1.2506\n",
            "Epoch 158/300, Average Training Loss: 1.3826\n",
            "Validation Loss: 1.2450\n",
            "Epoch 159/300, Average Training Loss: 1.3586\n",
            "Validation Loss: 1.2259\n",
            "Epoch 160/300, Average Training Loss: 1.3512\n",
            "Training Metrics after 160 epochs - SDR: -5.89, SIR: -7.62, SAR: 0.07, ISR: -3.33\n",
            "Validation Loss: 1.1574\n",
            "Epoch 161/300, Average Training Loss: 1.3040\n",
            "Validation Loss: 1.1686\n",
            "Epoch 162/300, Average Training Loss: 1.2810\n",
            "Validation Loss: 1.1709\n",
            "Epoch 163/300, Average Training Loss: 1.3090\n",
            "Validation Loss: 1.1681\n",
            "Epoch 164/300, Average Training Loss: 1.3049\n",
            "Validation Loss: 1.1723\n",
            "Epoch 165/300, Average Training Loss: 1.3347\n",
            "Validation Loss: 1.1741\n",
            "Epoch 166/300, Average Training Loss: 1.3150\n",
            "Validation Loss: 1.1718\n",
            "Epoch 167/300, Average Training Loss: 1.2966\n",
            "Validation Loss: 1.1746\n",
            "Epoch 168/300, Average Training Loss: 1.3182\n",
            "Validation Loss: 1.1755\n",
            "Epoch 169/300, Average Training Loss: 1.3090\n",
            "Validation Loss: 1.1706\n",
            "Epoch 170/300, Average Training Loss: 1.2977\n",
            "Training Metrics after 170 epochs - SDR: -5.86, SIR: -8.20, SAR: -0.22, ISR: -3.60\n",
            "Validation Loss: 1.1742\n",
            "Epoch 171/300, Average Training Loss: 1.3060\n",
            "Validation Loss: 1.1517\n",
            "Epoch 172/300, Average Training Loss: 1.2842\n",
            "Validation Loss: 1.1571\n",
            "Epoch 173/300, Average Training Loss: 1.2446\n",
            "Validation Loss: 1.1481\n",
            "Epoch 174/300, Average Training Loss: 1.2244\n",
            "Validation Loss: 1.1469\n",
            "Epoch 175/300, Average Training Loss: 1.2637\n",
            "Validation Loss: 1.1602\n",
            "Epoch 176/300, Average Training Loss: 1.2740\n",
            "Validation Loss: 1.1640\n",
            "Epoch 177/300, Average Training Loss: 1.2761\n",
            "Validation Loss: 1.1546\n",
            "Epoch 178/300, Average Training Loss: 1.2497\n",
            "Validation Loss: 1.1568\n",
            "Epoch 179/300, Average Training Loss: 1.2725\n",
            "Validation Loss: 1.1631\n",
            "Epoch 180/300, Average Training Loss: 1.2615\n",
            "Training Metrics after 180 epochs - SDR: -5.79, SIR: -7.86, SAR: 0.48, ISR: -3.59\n",
            "Validation Loss: 1.0929\n",
            "Epoch 181/300, Average Training Loss: 1.1856\n",
            "Validation Loss: 1.0705\n",
            "Epoch 182/300, Average Training Loss: 1.1617\n",
            "Validation Loss: 1.0610\n",
            "Epoch 183/300, Average Training Loss: 1.1896\n",
            "Validation Loss: 1.0600\n",
            "Epoch 184/300, Average Training Loss: 1.1858\n",
            "Validation Loss: 1.0692\n",
            "Epoch 185/300, Average Training Loss: 1.1616\n",
            "Validation Loss: 1.0691\n",
            "Epoch 186/300, Average Training Loss: 1.1634\n",
            "Validation Loss: 1.0663\n",
            "Epoch 187/300, Average Training Loss: 1.1652\n",
            "Validation Loss: 1.0773\n",
            "Epoch 188/300, Average Training Loss: 1.1345\n",
            "Validation Loss: 1.0684\n",
            "Epoch 189/300, Average Training Loss: 1.1727\n",
            "Validation Loss: 1.0678\n",
            "Epoch 190/300, Average Training Loss: 1.1382\n",
            "Training Metrics after 190 epochs - SDR: -5.79, SIR: -7.65, SAR: 2.13, ISR: -3.42\n",
            "Validation Loss: 0.9878\n",
            "Epoch 191/300, Average Training Loss: 1.1019\n",
            "Validation Loss: 0.9975\n",
            "Epoch 192/300, Average Training Loss: 1.0882\n",
            "Validation Loss: 0.9986\n",
            "Epoch 193/300, Average Training Loss: 1.0494\n",
            "Validation Loss: 0.9955\n",
            "Epoch 194/300, Average Training Loss: 1.0737\n",
            "Validation Loss: 0.9988\n",
            "Epoch 195/300, Average Training Loss: 1.0760\n",
            "Validation Loss: 0.9779\n",
            "Epoch 196/300, Average Training Loss: 1.0668\n",
            "Validation Loss: 0.9839\n",
            "Epoch 197/300, Average Training Loss: 1.0546\n",
            "Validation Loss: 0.9861\n",
            "Epoch 198/300, Average Training Loss: 1.0898\n",
            "Validation Loss: 1.0032\n",
            "Epoch 199/300, Average Training Loss: 1.0845\n",
            "Validation Loss: 1.0033\n",
            "Epoch 200/300, Average Training Loss: 1.0797\n",
            "Training Metrics after 200 epochs - SDR: -5.72, SIR: -7.50, SAR: 2.13, ISR: -3.53\n",
            "Validation Loss: 0.9185\n",
            "Epoch 201/300, Average Training Loss: 1.1494\n",
            "Validation Loss: 0.9395\n",
            "Epoch 202/300, Average Training Loss: 1.0174\n",
            "Validation Loss: 0.9342\n",
            "Epoch 203/300, Average Training Loss: 1.0021\n",
            "Validation Loss: 0.9474\n",
            "Epoch 204/300, Average Training Loss: 1.0119\n",
            "Validation Loss: 0.9262\n",
            "Epoch 205/300, Average Training Loss: 1.0056\n",
            "Validation Loss: 0.9120\n",
            "Epoch 206/300, Average Training Loss: 1.0016\n",
            "Validation Loss: 0.9088\n",
            "Epoch 207/300, Average Training Loss: 0.9810\n",
            "Validation Loss: 0.9233\n",
            "Epoch 208/300, Average Training Loss: 0.9985\n",
            "Validation Loss: 0.9825\n",
            "Epoch 209/300, Average Training Loss: 0.9652\n",
            "Validation Loss: 0.9446\n",
            "Epoch 210/300, Average Training Loss: 0.9685\n",
            "Training Metrics after 210 epochs - SDR: -5.88, SIR: -8.06, SAR: -0.39, ISR: -3.76\n",
            "Validation Loss: 0.9287\n",
            "Epoch 211/300, Average Training Loss: 1.0736\n",
            "Validation Loss: 0.9035\n",
            "Epoch 212/300, Average Training Loss: 0.9599\n",
            "Validation Loss: 0.9175\n",
            "Epoch 213/300, Average Training Loss: 0.9882\n",
            "Validation Loss: 0.9549\n",
            "Epoch 214/300, Average Training Loss: 0.9983\n",
            "Validation Loss: 0.9256\n",
            "Epoch 215/300, Average Training Loss: 0.9723\n",
            "Validation Loss: 0.8998\n",
            "Epoch 216/300, Average Training Loss: 0.9657\n",
            "Validation Loss: 0.9334\n",
            "Epoch 217/300, Average Training Loss: 0.9376\n",
            "Validation Loss: 0.9012\n",
            "Epoch 218/300, Average Training Loss: 0.9641\n",
            "Validation Loss: 0.9171\n",
            "Epoch 219/300, Average Training Loss: 0.9446\n",
            "Validation Loss: 0.8802\n",
            "Epoch 220/300, Average Training Loss: 0.9386\n",
            "Training Metrics after 220 epochs - SDR: -5.77, SIR: -8.07, SAR: 2.06, ISR: -3.54\n",
            "Validation Loss: 0.8604\n",
            "Epoch 221/300, Average Training Loss: 0.8871\n",
            "Validation Loss: 0.8521\n",
            "Epoch 222/300, Average Training Loss: 0.8940\n",
            "Validation Loss: 0.8402\n",
            "Epoch 223/300, Average Training Loss: 0.8748\n",
            "Validation Loss: 0.8492\n",
            "Epoch 224/300, Average Training Loss: 0.8725\n",
            "Validation Loss: 0.8307\n",
            "Epoch 225/300, Average Training Loss: 0.8614\n",
            "Validation Loss: 0.8330\n",
            "Epoch 226/300, Average Training Loss: 0.8660\n",
            "Validation Loss: 0.8417\n",
            "Epoch 227/300, Average Training Loss: 0.8671\n",
            "Validation Loss: 0.8333\n",
            "Epoch 228/300, Average Training Loss: 0.8715\n",
            "Validation Loss: 0.8323\n",
            "Epoch 229/300, Average Training Loss: 0.8524\n",
            "Validation Loss: 0.8241\n",
            "Epoch 230/300, Average Training Loss: 0.8479\n",
            "Training Metrics after 230 epochs - SDR: -5.78, SIR: -8.31, SAR: 2.69, ISR: -3.32\n",
            "Validation Loss: 0.7706\n",
            "Epoch 231/300, Average Training Loss: 0.8231\n",
            "Validation Loss: 0.7927\n",
            "Epoch 232/300, Average Training Loss: 0.8022\n",
            "Validation Loss: 0.7928\n",
            "Epoch 233/300, Average Training Loss: 0.8173\n",
            "Validation Loss: 0.7797\n",
            "Epoch 234/300, Average Training Loss: 0.8102\n",
            "Validation Loss: 0.7845\n",
            "Epoch 235/300, Average Training Loss: 0.8150\n",
            "Validation Loss: 0.7790\n",
            "Epoch 236/300, Average Training Loss: 0.8016\n",
            "Validation Loss: 0.7723\n",
            "Epoch 237/300, Average Training Loss: 0.7928\n",
            "Validation Loss: 0.7801\n",
            "Epoch 238/300, Average Training Loss: 0.7966\n",
            "Validation Loss: 0.7719\n",
            "Epoch 239/300, Average Training Loss: 0.7962\n",
            "Validation Loss: 0.7778\n",
            "Epoch 240/300, Average Training Loss: 0.7950\n",
            "Training Metrics after 240 epochs - SDR: -5.75, SIR: -8.49, SAR: 3.01, ISR: -3.11\n",
            "Validation Loss: 0.7120\n",
            "Epoch 241/300, Average Training Loss: 0.7390\n",
            "Validation Loss: 0.7115\n",
            "Epoch 242/300, Average Training Loss: 0.7393\n",
            "Validation Loss: 0.7090\n",
            "Epoch 243/300, Average Training Loss: 0.7341\n",
            "Validation Loss: 0.7113\n",
            "Epoch 244/300, Average Training Loss: 0.7520\n",
            "Validation Loss: 0.7205\n",
            "Epoch 245/300, Average Training Loss: 0.7430\n",
            "Validation Loss: 0.7134\n",
            "Epoch 246/300, Average Training Loss: 0.7456\n",
            "Validation Loss: 0.7171\n",
            "Epoch 247/300, Average Training Loss: 0.7369\n",
            "Validation Loss: 0.7031\n",
            "Epoch 248/300, Average Training Loss: 0.7380\n",
            "Validation Loss: 0.7088\n",
            "Epoch 249/300, Average Training Loss: 0.7406\n",
            "Validation Loss: 0.7142\n",
            "Epoch 250/300, Average Training Loss: 0.7408\n",
            "Training Metrics after 250 epochs - SDR: -5.72, SIR: -8.64, SAR: 3.67, ISR: -2.89\n",
            "Validation Loss: 0.6696\n",
            "Epoch 251/300, Average Training Loss: 0.6900\n",
            "Validation Loss: 0.6647\n",
            "Epoch 252/300, Average Training Loss: 0.6935\n",
            "Validation Loss: 0.6633\n",
            "Epoch 253/300, Average Training Loss: 0.6935\n",
            "Validation Loss: 0.6556\n",
            "Epoch 254/300, Average Training Loss: 0.6848\n",
            "Validation Loss: 0.6609\n",
            "Epoch 255/300, Average Training Loss: 0.6863\n",
            "Validation Loss: 0.6622\n",
            "Epoch 256/300, Average Training Loss: 0.6850\n",
            "Validation Loss: 0.6647\n",
            "Epoch 257/300, Average Training Loss: 0.6870\n",
            "Validation Loss: 0.6608\n",
            "Epoch 258/300, Average Training Loss: 0.6791\n",
            "Validation Loss: 0.6553\n",
            "Epoch 259/300, Average Training Loss: 0.6820\n",
            "Validation Loss: 0.6590\n",
            "Epoch 260/300, Average Training Loss: 0.6860\n",
            "Training Metrics after 260 epochs - SDR: -5.69, SIR: -8.52, SAR: 4.74, ISR: -2.80\n",
            "Validation Loss: 0.6132\n",
            "Epoch 261/300, Average Training Loss: 0.6497\n",
            "Validation Loss: 0.6185\n",
            "Epoch 262/300, Average Training Loss: 0.6459\n",
            "Validation Loss: 0.6191\n",
            "Epoch 263/300, Average Training Loss: 0.6418\n",
            "Validation Loss: 0.6098\n",
            "Epoch 264/300, Average Training Loss: 0.6308\n",
            "Validation Loss: 0.6119\n",
            "Epoch 265/300, Average Training Loss: 0.6401\n",
            "Validation Loss: 0.6187\n",
            "Epoch 266/300, Average Training Loss: 0.6419\n",
            "Validation Loss: 0.6222\n",
            "Epoch 267/300, Average Training Loss: 0.6465\n",
            "Validation Loss: 0.6167\n",
            "Epoch 268/300, Average Training Loss: 0.6395\n",
            "Validation Loss: 0.6135\n",
            "Epoch 269/300, Average Training Loss: 0.6513\n",
            "Validation Loss: 0.6193\n",
            "Epoch 270/300, Average Training Loss: 0.6446\n",
            "Training Metrics after 270 epochs - SDR: -5.71, SIR: -8.52, SAR: 5.53, ISR: -2.87\n",
            "Validation Loss: 0.5813\n",
            "Epoch 271/300, Average Training Loss: 0.5998\n",
            "Validation Loss: 0.5803\n",
            "Epoch 272/300, Average Training Loss: 0.6152\n",
            "Validation Loss: 0.5943\n",
            "Epoch 273/300, Average Training Loss: 0.6063\n",
            "Validation Loss: 0.5847\n",
            "Epoch 274/300, Average Training Loss: 0.6128\n",
            "Validation Loss: 0.5858\n",
            "Epoch 275/300, Average Training Loss: 0.6075\n",
            "Validation Loss: 0.5842\n",
            "Epoch 276/300, Average Training Loss: 0.6052\n",
            "Validation Loss: 0.5898\n",
            "Epoch 277/300, Average Training Loss: 0.6061\n",
            "Validation Loss: 0.5801\n",
            "Epoch 278/300, Average Training Loss: 0.5984\n",
            "Validation Loss: 0.5822\n",
            "Epoch 279/300, Average Training Loss: 0.6032\n",
            "Validation Loss: 0.5872\n",
            "Epoch 280/300, Average Training Loss: 0.6061\n",
            "Training Metrics after 280 epochs - SDR: -5.67, SIR: -8.55, SAR: 6.25, ISR: -2.83\n",
            "Validation Loss: 0.5475\n",
            "Epoch 281/300, Average Training Loss: 0.5743\n",
            "Validation Loss: 0.5569\n",
            "Epoch 282/300, Average Training Loss: 0.5702\n",
            "Validation Loss: 0.5574\n",
            "Epoch 283/300, Average Training Loss: 0.5723\n",
            "Validation Loss: 0.5523\n",
            "Epoch 284/300, Average Training Loss: 0.5676\n",
            "Validation Loss: 0.5540\n",
            "Epoch 285/300, Average Training Loss: 0.5685\n",
            "Validation Loss: 0.5458\n",
            "Epoch 286/300, Average Training Loss: 0.5705\n",
            "Validation Loss: 0.5521\n",
            "Epoch 287/300, Average Training Loss: 0.5675\n",
            "Validation Loss: 0.5521\n",
            "Epoch 288/300, Average Training Loss: 0.5646\n",
            "Validation Loss: 0.5457\n",
            "Epoch 289/300, Average Training Loss: 0.5679\n",
            "Validation Loss: 0.5520\n",
            "Epoch 290/300, Average Training Loss: 0.5637\n",
            "Training Metrics after 290 epochs - SDR: -5.67, SIR: -8.74, SAR: 6.92, ISR: -2.69\n",
            "Validation Loss: 0.5261\n",
            "Epoch 291/300, Average Training Loss: 0.5442\n",
            "Validation Loss: 0.5347\n",
            "Epoch 292/300, Average Training Loss: 0.5417\n",
            "Validation Loss: 0.5276\n",
            "Epoch 293/300, Average Training Loss: 0.5496\n",
            "Validation Loss: 0.5373\n",
            "Epoch 294/300, Average Training Loss: 0.5427\n",
            "Validation Loss: 0.5206\n",
            "Epoch 295/300, Average Training Loss: 0.5435\n",
            "Validation Loss: 0.5273\n",
            "Epoch 296/300, Average Training Loss: 0.5396\n",
            "Validation Loss: 0.5299\n",
            "Epoch 297/300, Average Training Loss: 0.5395\n",
            "Validation Loss: 0.5180\n",
            "Epoch 298/300, Average Training Loss: 0.5360\n",
            "Validation Loss: 0.5308\n",
            "Epoch 299/300, Average Training Loss: 0.5404\n",
            "Validation Loss: 0.5236\n",
            "Epoch 300/300, Average Training Loss: 0.5416\n",
            "Training Metrics after 300 epochs - SDR: -5.67, SIR: -8.83, SAR: 7.15, ISR: -2.78\n",
            "Validation Loss: 0.5036\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "def validate_model(model, dataloader, criterion, device, weights):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    total_loss = 0  # Initialize total loss\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient computation\n",
        "        for batch_idx, (data, targets) in enumerate(dataloader):\n",
        "            data = inspect_and_prepare_data(data).to(device)  # Prepare and move data to device\n",
        "            targets = inspect_and_prepare_data(targets, is_target=True).to(device)  # Prepare and move targets to device\n",
        "            outputs = model(data)  # Get model outputs\n",
        "            loss = criterion(outputs, targets, weights)  # Compute loss\n",
        "            total_loss += loss.item()  # Accumulate loss\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)  # Compute average loss\n",
        "    print(f'Validation Loss: {avg_loss:.4f}')\n",
        "    return avg_loss  # Return the average loss\n",
        "\n",
        "def train_model(model, train_loader, valid_loader, criterion, optimizer, scheduler, device, weights, loss_metric_mapping, epochs=10):\n",
        "    train_losses = []  # List to store training losses\n",
        "    valid_losses = []  # List to store validation losses\n",
        "    metrics = {'sdr': [], 'sir': [], 'sar': [], 'isr': []}  # Dictionary to store metrics\n",
        "    best_val_loss = float('inf')  # Initialize best validation loss\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()  # Set the model to training mode\n",
        "        total_train_loss = 0  # Initialize total training loss\n",
        "\n",
        "        for batch_idx, (data, targets) in enumerate(train_loader):\n",
        "            data = inspect_and_prepare_data(data).to(device)  # Prepare and move data to device\n",
        "            targets = inspect_and_prepare_data(targets, is_target=True).to(device)  # Prepare and move targets to device\n",
        "\n",
        "            optimizer.zero_grad()  # Zero the gradients\n",
        "            outputs = model(data)  # Get model outputs\n",
        "            loss = criterion(outputs, targets, weights)  # Compute loss\n",
        "            loss.backward()  # Backpropagate the loss\n",
        "            optimizer.step()  # Update the model parameters\n",
        "            total_train_loss += loss.item()  # Accumulate training loss\n",
        "\n",
        "        avg_train_loss = total_train_loss / len(train_loader)  # Compute average training loss\n",
        "        train_losses.append(avg_train_loss)  # Append average training loss to the list\n",
        "        print(f'Epoch {epoch+1}/{epochs}, Average Training Loss: {avg_train_loss:.4f}')  # Print average training loss\n",
        "\n",
        "        # Every 10 epochs, compute metrics for training data\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            sdr, sir, sar, isr = [], [], [], []  # Initialize metrics lists\n",
        "            try:\n",
        "                model.eval()  # Set the model to evaluation mode for metric computation\n",
        "                with torch.no_grad():\n",
        "                    for batch_idx, (data, targets) in enumerate(train_loader):\n",
        "                        data = inspect_and_prepare_data(data).to(device)  # Prepare and move data to device\n",
        "                        targets = inspect_and_prepare_data(targets, is_target=True).to(device)  # Prepare and move targets to device\n",
        "\n",
        "                        outputs = model(data)  # Get model outputs\n",
        "\n",
        "                        for i in range(outputs.shape[0]):  # Iterate over the batch\n",
        "                            # Invert the spectrogram to get audio\n",
        "                            outputs_audio = [invert_spectrogram(outputs[i, s].unsqueeze(-1), device=device) for s in range(outputs.shape[1])]\n",
        "                            targets_audio = [invert_spectrogram(targets[i, s].unsqueeze(-1), device=device) for s in range(targets.shape[1])]\n",
        "\n",
        "                            est_segments = []  # Estimated segments for BSS Eval\n",
        "                            ref_segments = []  # Reference segments for BSS Eval\n",
        "\n",
        "                            for est, ref in zip(outputs_audio, targets_audio):\n",
        "                                est = est.detach().cpu().numpy().flatten()  # Convert to numpy and flatten\n",
        "                                ref = ref.detach().cpu().numpy().flatten()  # Convert to numpy and flatten\n",
        "\n",
        "                                est_segments.append(est)  # Append estimated segment\n",
        "                                ref_segments.append(ref)  # Append reference segment\n",
        "\n",
        "                            if len(est_segments) == 0 or len(ref_segments) == 0:  # Skip if any segment is empty\n",
        "                                continue\n",
        "\n",
        "                            est_segments = np.stack(est_segments)  # Stack estimated segments\n",
        "                            ref_segments = np.stack(ref_segments)  # Stack reference segments\n",
        "\n",
        "                            # Adding epsilon to prevent division by zero\n",
        "                            epsilon = 1e-8\n",
        "                            sdr_vals, isr_vals, sir_vals, sar_vals, _ = mir_eval.separation.bss_eval_images(\n",
        "                                ref_segments + epsilon, est_segments + epsilon, compute_permutation=False\n",
        "                            )\n",
        "                            sdr.extend(sdr_vals)  # Extend SDR values\n",
        "                            isr.extend(isr_vals)  # Extend ISR values\n",
        "                            sir.extend(sir_vals)  # Extend SIR values\n",
        "                            sar.extend(sar_vals)  # Extend SAR values\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing track: {e}\")  # Print error message\n",
        "\n",
        "            # Compute average training metrics\n",
        "            avg_sdr = np.mean(sdr) if sdr else float('nan')\n",
        "            avg_sir = np.mean(sir) if sir else float('nan')\n",
        "            avg_sar = np.mean(sar) if sar else float('nan')\n",
        "            avg_isr = np.mean(isr) if isr else float('nan')\n",
        "            metrics['sdr'].append(avg_sdr)  # Append average SDR\n",
        "            metrics['sir'].append(avg_sir)  # Append average SIR\n",
        "            metrics['sar'].append(avg_sar)  # Append average SAR\n",
        "            metrics['isr'].append(avg_isr)  # Append average ISR\n",
        "\n",
        "            print(f'Training Metrics after {epoch+1} epochs - SDR: {avg_sdr:.2f}, SIR: {avg_sir:.2f}, SAR: {avg_sar:.2f}, ISR: {avg_isr:.2f}')  # Print training metrics\n",
        "\n",
        "            # Update weights using training metrics\n",
        "            weights = update_weights(weights, metrics, loss_metric_mapping)\n",
        "\n",
        "        # Compute validation loss\n",
        "        validation_loss = validate_model(model, valid_loader, criterion, device, weights)\n",
        "        valid_losses.append(validation_loss)  # Append validation loss\n",
        "\n",
        "        # Update best model if validation loss improves\n",
        "        if validation_loss < best_val_loss:\n",
        "            best_val_loss = validation_loss\n",
        "            torch.save(model.state_dict(), save_path)  # Save the model state\n",
        "\n",
        "        # Step the learning rate scheduler\n",
        "        scheduler.step()\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()  # Collect garbage\n",
        "\n",
        "    # Plotting training and validation loss and metrics\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    plt.subplot(2, 1, 1)\n",
        "    plt.plot(train_losses, label='Training Loss')  # Plot training loss\n",
        "    plt.plot(valid_losses, label='Validation Loss')  # Plot validation loss\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(2, 1, 2)\n",
        "    plt.plot(metrics['sdr'], label='SDR')  # Plot SDR metric\n",
        "    plt.plot(metrics['sir'], label='SIR')  # Plot SIR metric\n",
        "    plt.plot(metrics['sar'], label='SAR')  # Plot SAR metric\n",
        "    plt.plot(metrics['isr'], label='ISR')  # Plot ISR metric\n",
        "    plt.title('Source Separation Metrics')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Metric')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Set the number of epochs\n",
        "epoch_num = 300\n",
        "\n",
        "# Set the device to GPU if available, otherwise use CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Initialize the model\n",
        "model = EnhancedUNet(in_channels=2, num_sources=4, dropout_prob=0.3).to(device)\n",
        "\n",
        "# Define the loss criterion\n",
        "criterion = custom_loss\n",
        "\n",
        "# Initialize the optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00001, weight_decay=0.01)\n",
        "\n",
        "# Initialize the learning rate scheduler\n",
        "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.01, steps_per_epoch=len(train_loader), epochs=epoch_num)\n",
        "\n",
        "# Define the initial weights for the custom loss\n",
        "initial_weights = {\n",
        "    'spec_weight': 0.2,\n",
        "    'mag_weight': 0.2,\n",
        "    'phase_weight': 0.2,\n",
        "    'interference_weight': 0.1,\n",
        "    'artifacts_weight': 0.3\n",
        "}\n",
        "\n",
        "# Normalize the initial weights\n",
        "initial_weights = normalize_weights(initial_weights)\n",
        "\n",
        "# Map loss components to metrics for weight adjustment\n",
        "loss_metric_mapping = {\n",
        "    'spec_weight': 'sdr',\n",
        "    'mag_weight': 'sir',\n",
        "    'phase_weight': 'sar',\n",
        "    'interference_weight': 'isr',\n",
        "    'artifacts_weight': 'sar'\n",
        "}\n",
        "\n",
        "\n",
        "summary(model, input_size=(2, 513, 1292))\n",
        "save_path = \"/content/drive/MyDrive/musdb18/model_parameters.pt\"\n",
        "train_model(model, train_loader, valid_loader, criterion, optimizer, scheduler, device, initial_weights, loss_metric_mapping, epochs=epoch_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4r_in75W8kQn"
      },
      "outputs": [],
      "source": [
        "# Specify the directory containing .pt files and the path to the new HDF5 file\n",
        "pt_directory = '/content/drive/MyDrive/musdb18/test_spectrograms'\n",
        "test_hdf5_path = '/content/drive/MyDrive/musdb18/test_spectrograms_hdf5'\n",
        "\n",
        "# Convert the files\n",
        "convert_pt_to_hdf5(pt_directory, test_hdf5_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9WglPbdrAF0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efca5a66-4b16-41e7-8188-3a1f1df52316"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source: bass - Average SDR: 0.11, Average SIR: inf, Average SAR: 5.73, Average ISR: 0.15\n",
            "Source: drums - Average SDR: 0.85, Average SIR: -5.74, Average SAR: 7.74, Average ISR: 1.29\n",
            "Source: other - Average SDR: 1.66, Average SIR: -0.78, Average SAR: 7.69, Average ISR: 2.64\n",
            "Source: vocals - Average SDR: 0.90, Average SIR: -5.51, Average SAR: 7.65, Average ISR: 1.47\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'bass': 0.11094596923192726,\n",
              "  'drums': 0.846125513233099,\n",
              "  'other': 1.656942784601498,\n",
              "  'vocals': 0.9044294983168595},\n",
              " {'bass': inf,\n",
              "  'drums': -5.742665774563841,\n",
              "  'other': -0.7827459701417602,\n",
              "  'vocals': -5.505653216220356},\n",
              " {'bass': 5.733983932535275,\n",
              "  'drums': 7.736156682456919,\n",
              "  'other': 7.692274948511468,\n",
              "  'vocals': 7.654330429661234},\n",
              " {'bass': 0.14773192944209704,\n",
              "  'drums': 1.2935064593542538,\n",
              "  'other': 2.6351925735360635,\n",
              "  'vocals': 1.4745686370063953})"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "def evaluate_model(model, test_loader, device, num_sources, source_names):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    sample_rate = 22050\n",
        "    epsilon = 1e-8\n",
        "\n",
        "    # Initialize lists to store metrics for each source\n",
        "    all_sdr = {source: [] for source in source_names}\n",
        "    all_sir = {source: [] for source in source_names}\n",
        "    all_sar = {source: [] for source in source_names}\n",
        "    all_isr = {source: [] for source in source_names}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, targets) in enumerate(test_loader):\n",
        "            data = inspect_and_prepare_data(data).to(device)\n",
        "            targets = inspect_and_prepare_data(targets, is_target=True).to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(data)\n",
        "\n",
        "            for i in range(outputs.shape[0]):  # Iterate over each sample in the batch\n",
        "                outputs_audio = [invert_spectrogram(outputs[i, s].unsqueeze(-1), device=device) for s in range(outputs.shape[1])]\n",
        "                targets_audio = [invert_spectrogram(targets[i, s].unsqueeze(-1), device=device) for s in range(targets.shape[1])]\n",
        "\n",
        "                est_segments = []  # Estimated segments for BSS Eval\n",
        "                ref_segments = []  # Reference segments for BSS Eval\n",
        "\n",
        "                for est, ref in zip(outputs_audio, targets_audio):\n",
        "                    est = est.cpu().numpy().flatten()\n",
        "                    ref = ref.cpu().numpy().flatten()\n",
        "\n",
        "                    # Skip silent reference sources\n",
        "                    if np.all(ref == 0):\n",
        "                        continue\n",
        "\n",
        "                    est_segments.append(est)\n",
        "                    ref_segments.append(ref)\n",
        "\n",
        "                if len(est_segments) == 0 or len(ref_segments) == 0:\n",
        "                    continue\n",
        "\n",
        "                est_segments = np.stack(est_segments)\n",
        "                ref_segments = np.stack(ref_segments)\n",
        "\n",
        "                try:\n",
        "                    # Adding epsilon to prevent division by zero\n",
        "                    sdr_vals, isr_vals, sir_vals, sar_vals, _ = mir_eval.separation.bss_eval_images(\n",
        "                        ref_segments + epsilon, est_segments + epsilon, compute_permutation=False\n",
        "                    )\n",
        "                    for s, source in enumerate(source_names):\n",
        "                        if s < len(sdr_vals):  # Ensure there are enough values to prevent index out of bounds\n",
        "                            all_sdr[source].append(sdr_vals[s])\n",
        "                            all_sir[source].append(sir_vals[s])\n",
        "                            all_sar[source].append(sar_vals[s])\n",
        "                            all_isr[source].append(isr_vals[s])\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing track: {e}\")\n",
        "\n",
        "    # Compute average metrics for each source\n",
        "    avg_sdr = {source: np.mean(all_sdr[source]) if all_sdr[source] else float('nan') for source in source_names}\n",
        "    avg_sir = {source: np.mean(all_sir[source]) if all_sir[source] else float('nan') for source in source_names}\n",
        "    avg_sar = {source: np.mean(all_sar[source]) if all_sar[source] else float('nan') for source in source_names}\n",
        "    avg_isr = {source: np.mean(all_isr[source]) if all_isr[source] else float('nan') for source in source_names}\n",
        "\n",
        "    for source in source_names:\n",
        "        print(f'Source: {source} - Average SDR: {avg_sdr[source]:.2f}, Average SIR: {avg_sir[source]:.2f}, Average SAR: {avg_sar[source]:.2f}, Average ISR: {avg_isr[source]:.2f}')\n",
        "\n",
        "    return avg_sdr, avg_sir, avg_sar, avg_isr\n",
        "\n",
        "\n",
        "# Get the list of unique track base names from the HDF5 file\n",
        "test_tracks = get_unique_track_names('/content/drive/MyDrive/musdb18/test_spectrograms_hdf5')\n",
        "\n",
        "# Determine the total number of tracks to use\n",
        "total_tracks = min(50, len(test_tracks))\n",
        "\n",
        "# Define the path to the HDF5 file\n",
        "test_hdf5_path = '/content/drive/MyDrive/musdb18/test_spectrograms_hdf5'\n",
        "\n",
        "# Create training and validation datasets with the corresponding track names and transformations\n",
        "test_dataset = AudioDataset(hdf5_path=test_hdf5_path, track_list=test_tracks, transform=None)\n",
        "\n",
        "# Create DataLoader for the training dataset\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        "    pin_memory=True,\n",
        "    collate_fn=pad_and_collate\n",
        ")\n",
        "\n",
        "source_names = ['bass', 'drums', 'other', 'vocals']  # Define the source names in order\n",
        "num_sources = 4  # Define the number of sources in your dataset\n",
        "evaluate_model(model, test_loader, device, num_sources, source_names)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_bass_sir(model, test_loader, device):\n",
        "    model.eval()\n",
        "    sample_rate = 22050\n",
        "    epsilon = 1e-8\n",
        "\n",
        "    all_sir = []  # Initialize list\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, targets) in enumerate(test_loader):\n",
        "            data = inspect_and_prepare_data(data).to(device)  # Prepare and move data to device\n",
        "            targets = inspect_and_prepare_data(targets, is_target=True).to(device)  # Prepare and move targets to device\n",
        "\n",
        "            outputs = model(data)\n",
        "\n",
        "            for i in range(outputs.shape[0]):  # Iterate over each sample in the batch\n",
        "                outputs_audio = [invert_spectrogram(outputs[i, s].unsqueeze(-1), device=device) for s in range(outputs.shape[1])]\n",
        "                targets_audio = [invert_spectrogram(targets[i, s].unsqueeze(-1), device=device) for s in range(targets.shape[1])]\n",
        "\n",
        "                est_segments = []  # Estimated segments for BSS Eval\n",
        "                ref_segments = []  # Reference segments for BSS Eval\n",
        "\n",
        "                for est, ref in zip(outputs_audio, targets_audio):\n",
        "                    est = est.cpu().numpy().flatten()\n",
        "                    ref = ref.cpu().numpy().flatten()\n",
        "\n",
        "                    # Skip silent reference sources\n",
        "                    if np.all(ref == 0) or np.all(est == 0):\n",
        "                        continue\n",
        "\n",
        "                    est_segments.append(est)\n",
        "                    ref_segments.append(ref)\n",
        "\n",
        "                if len(est_segments) == 0 or len(ref_segments) == 0:\n",
        "                    continue\n",
        "\n",
        "                est_segments = np.stack(est_segments)\n",
        "                ref_segments = np.stack(ref_segments)\n",
        "\n",
        "                try:\n",
        "                    # Adding epsilon to prevent division by zero\n",
        "                    sdr_vals, isr_vals, sir_vals, sar_vals, _ = mir_eval.separation.bss_eval_images(\n",
        "                        ref_segments + epsilon, est_segments + epsilon, compute_permutation=False\n",
        "                    )\n",
        "                    for s, source in enumerate(source_names):\n",
        "                        if s < len(sir_vals):  # Ensure there are enough values to prevent index out of bounds\n",
        "                            if source == \"bass\":  # Check if the source is bass\n",
        "                                if not np.isinf(sir_vals[s]):  # Skip inf values\n",
        "                                    all_sir.append(sir_vals[s])\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing track: {e}\")\n",
        "\n",
        "    avg_sir = np.mean(all_sir) if all_sir else float('nan')  # Compute average SIR for bass\n",
        "    print(f'Bass - Average SIR: {avg_sir:.2f}')\n",
        "\n",
        "    return avg_sir\n",
        "\n",
        "avg_bass_sir = evaluate_bass_sir(model, test_loader, device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwZZWmscPTyQ",
        "outputId": "a5b7bd18-fe03-486d-fc3e-346f3c31c32c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bass - Average SIR: -14.92\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "1r7AW5tnbFA7VWWgb-I7eACct81N1yA6H",
      "authorship_tag": "ABX9TyOBGbwrxXpZQAkdYE6SlcPP",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}